,name,value,description
0,io.bytes.per.checksum,-957067377,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.batched.ls.limit,100,"Limit the number of paths that can be listed in a single batched
    listing call. printed by ls. If less or equal to
    zero, at most DFS_LIST_LIMIT_DEFAULT (= 1000) will be printed."
2,yarn.timeline-service.writer.flush-interval-seconds,60,
3,hadoop.hdfs.configuration.version,1,version of this configuration file
4,dfs.datanode.directoryscan.threads,1,"How many threads should the threadpool used to compile reports
  for volumes in parallel have."
5,dfs.provided.aliasmap.load.retries,0,"The number of retries on the Datanode to load the provided aliasmap;
      defaults to 0."
6,dfs.client.write.byte-array-manager.count-threshold,128,"The count threshold for each array length so that a manager is created only after the
    allocation count exceeds the threshold. In other words, the particular array length
    is not managed until the allocation count exceeds the threshold."
7,dfs.namenode.decommission.blocks.per.interval,500000,"The approximate number of blocks to process per decommission
    or maintenance interval, as defined in dfs.namenode.decommission.interval."
8,yarn.nodemanager.node-attributes.provider.fetch-timeout-ms,1200000,
9,dfs.namenode.max-corrupt-file-blocks-returned,100,"The maximum number of corrupt file blocks listed by NameNode Web UI,
      JMX and other client request."
