,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb,0,
2,yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs,86400,
3,dfs.storage.policy.satisfier.work.multiplier.per.iteration,1,"*Note*: Advanced property. Change with caution.
    This determines the total amount of block transfers to begin in
    one iteration, for satisfy the policy. The actual number is obtained by
    multiplying this multiplier with the total number of live nodes in the
    cluster. The result number is the number of blocks to begin transfers
    immediately. This number can be any positive, non-zero integer."
4,dfs.namenode.decommission.backoff.monitor.pending.limit,10000,"When the Backoff monitor is enabled, determines the maximum number of blocks
    related to decommission and maintenance operations that can be loaded
    into the replication queue at any given time. Every
    dfs.namenode.decommission.interval seconds, the list is checked to see if
    the blocks have become fully replicated and then further blocks are added
    to reach the limit defined in this parameter."
5,yarn.nodemanager.resource.memory.cgroups.swappiness,0,
6,hadoop.registry.zk.connection.timeout.ms,15000,Zookeeper connection timeout in milliseconds
7,yarn.timeline-service.client.fd-clean-interval-secs,60,
8,dfs.replication.max,512,Maximal block replication.
9,dfs.datanode.data.transfer.bandwidthPerSec,0,"Specifies the maximum amount of bandwidth that the data transfering can utilize for transfering block when
      BlockConstructionStage is
      PIPELINE_SETUP_CREATE and clientName is empty.
      When the bandwidth value is zero, there is no limit."
