,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.client.socketcache.expiryMsec,3000,Socket cache expiration for short-circuit reads in msec.
2,dfs.namenode.fs-limits.max-directory-items,1048576,"Defines the maximum number of items that a directory may
      contain. Cannot set the property to a value less than 1 or more than
      6400000."
3,fs.s3a.socket.recv.buffer,8192,Socket receive buffer hint to amazon connector. Represented in bytes.
4,dfs.client.failover.sleep.max.millis,15000,"Expert only. The time to wait, in milliseconds, between failover
    attempts increases exponentially as a function of the number of
    attempts made so far, with a random factor of +/- 50%. This option
    specifies the maximum value to wait between failovers. 
    Specifically, the time between two failover attempts will not
    exceed +/- 50% of dfs.client.failover.sleep.max.millis
    milliseconds."
5,dfs.ha.zkfc.port,8019,"The port number that the zookeeper failover controller RPC
    server binds to."
6,dfs.ls.limit,1000,"Limit the number of files printed by ls. If less or equal to
    zero, at most DFS_LIST_LIMIT_DEFAULT (= 1000) will be printed."
7,mapreduce.job.ubertask.maxreduces,1,"Threshold for number of reduces, beyond which job is considered
  too big for the ubertasking optimization.  CURRENTLY THE CODE CANNOT SUPPORT
  MORE THAN ONE REDUCE and will ignore larger values.  (Zero is a valid max,
  however.)  Users may override this value, but only downward."
8,dfs.ha.tail-edits.namenode-retries,3,Number of retries to use when contacting the namenode when tailing the log.
9,dfs.datanode.data.write.bandwidthPerSec,0,"Specifies the maximum amount of bandwidth that the data transfering can utilize for writing block or pipeline
      recovery when
      BlockConstructionStage is PIPELINE_SETUP_APPEND_RECOVERY or PIPELINE_SETUP_STREAMING_RECOVERY.
      When the bandwidth value is zero, there is no limit."
