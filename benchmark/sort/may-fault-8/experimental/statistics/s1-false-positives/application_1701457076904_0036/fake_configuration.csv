,name,value,description
0,hadoop.registry.zk.retry.interval.ms,W83lj,<missing>
1,yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms,600000,
2,dfs.namenode.fs-limits.min-block-size,1048576,"Minimum block size in bytes, enforced by the Namenode at create
      time. This prevents the accidental creation of files with tiny block
      sizes (and thus many blocks), which can degrade performance. Support multiple
      size unit suffix(case insensitive), as described in dfs.blocksize."
3,yarn.nodemanager.localizer.cache.cleanup.interval-ms,600000,
4,yarn.sharedcache.store.in-memory.staleness-period-mins,10080,
5,mapreduce.am.max-attempts,2,"The maximum number of application attempts. It is a
  application-specific setting. It should not be larger than the global number
  set by resourcemanager. Otherwise, it will be override. The default number is
  set to 2, to allow at least one retry for AM."
6,dfs.http.client.failover.max.attempts,15,"Specify the max number of failover attempts for WebHDFS client
    in case of network exception."
7,ipc.maximum.response.length,134217728,"This indicates the maximum IPC message length (bytes) that can be
    accepted by the client. Messages larger than this value are rejected
    immediately to avoid possible OOMs. This setting should rarely need to be
    changed.  Set to 0 to disable."
8,yarn.log-aggregation-status.time-out.ms,600000,
