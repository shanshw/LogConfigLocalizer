,name,value,description
0,dfs.balancer.max-size-to-move,nXH4k,"Maximum number of bytes that can be moved by the balancer in a single
    thread."
1,mapreduce.shuffle.pathcache.concurrency-level,16,"Uses the concurrency level to create a fixed number of hashtable
    segments, each governed by its own write lock."
2,yarn.app.mapreduce.client.job.max-retries,3,"The number of retries the client will make for getJob and
    dependent calls.
    This is needed for non-HDFS DFS where additional, high level
    retries are required to avoid spurious failures during the getJob call.
    30 is a good value for WASB"
3,dfs.namenode.audit.log.async.buffer.size,128,"Only used when enables asynchronous audit log. Sets the number of audit
    logs allowed in the event buffer before the calling thread is blocked
    (if dfs.namenode.audit.log.async.blocking is true) or until logs are
    summarized and discarded. Default value is 128."
4,dfs.datanode.min.outlier.detection.nodes,10,Minimum number of nodes to run outlier detection.
5,dfs.client.socket-timeout,60000,Default timeout value in milliseconds for all sockets.
6,yarn.timeline-service.client.fd-retain-secs,300,
7,dfs.disk.balancer.block.tolerance.percent,10,"When a disk balancer copy operation is proceeding, the datanode is still
      active. So it might not be possible to move the exactly specified
      amount of data. So tolerance allows us to define a percentage which
      defines a good enough move."
8,dfs.namenode.redundancy.queue.restart.iterations,2400,"When picking blocks from the low redundancy queues, reset the
    bookmarked iterator after the set number of iterations to ensure any blocks
    which were not processed on the first pass are retried before the iterators
    would naturally reach their end point. This ensures blocks are retried
    more frequently when there are many pending blocks or blocks are
    continuously added to the queues preventing the iterator reaching its
    natural endpoint.
    The default setting of 2400 combined with the default of
    dfs.namenode.redundancy.interval.seconds means the iterators will be reset
    approximately every 2 hours.
    Setting this parameter to zero disables the feature and the iterators will
    be reset only when the end of all queues has been reached."
9,dfs.datanode.network.counts.cache.max.size,2147483647,"The maximum number of entries the datanode per-host network error
    count cache may contain."
