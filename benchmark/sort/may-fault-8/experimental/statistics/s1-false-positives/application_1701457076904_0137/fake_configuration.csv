,name,value,description
0,dfs.datanode.directoryscan.interval,0,"Interval in seconds for Datanode to scan data directories and
  reconcile the difference between blocks in memory and on the disk.
  Support multiple time unit suffix(case insensitive), as described
  in dfs.heartbeat.interval.If no time unit is specified then seconds
  is assumed."
1,dfs.namenode.lease-recheck-interval-ms,2000,"During the release of lease a lock is hold that make any
    operations on the namenode stuck. In order to not block them during
    a too long duration we stop releasing lease after this max lock limit."
2,dfs.replication.max,512,Maximal block replication.
3,dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume,4,"The maximum number of threads per volume used to process async disk
    operations on the datanode. These threads consume I/O and CPU at the
    same time. This will affect normal data node operations."
4,fs.s3a.socket.send.buffer,8192,Socket send buffer hint to amazon connector. Represented in bytes.
5,dfs.datanode.max.transfer.threads,4096,"Specifies the maximum number of threads to use for transferring data
        in and out of the DN."
6,dfs.namenode.max.full.block.report.leases,6,"The maximum number of leases for full block reports that the
    NameNode will issue at any given time.  This prevents the NameNode from
    being flooded with full block reports that use up all the RPC handler
    threads.  This number should never be more than the number of RPC handler
    threads or less than 1."
7,dfs.datanode.slow.io.warning.threshold.ms,300,"The threshold in milliseconds at which we will log a slow
    io warning in a datanode. By default, this parameter is set to 300
    milliseconds."
8,mapreduce.map.maxattempts,4,"Expert: The maximum number of attempts per map task.
  In other words, framework will try to execute a map task these many number
  of times before giving up on it."
9,yarn.nodemanager.local-cache.max-files-per-directory,8192,
