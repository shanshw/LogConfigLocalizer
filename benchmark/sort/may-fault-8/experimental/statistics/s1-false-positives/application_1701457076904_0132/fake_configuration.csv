,name,value,description
0,io.bytes.per.checksum,,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min,3600,
2,dfs.storage.policy.satisfier.retry.max.attempts,3,"Max retry to satisfy the block storage policy. After this retry block will be removed
    from the movement needed queue."
3,dfs.namenode.available-space-rack-fault-tolerant-block-placement-policy.balanced-space-tolerance,5,"Only used when the dfs.block.replicator.classname is set to
    org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceRackFaultTolerantBlockPlacementPolicy.
    Special value between 0 and 20, inclusive. if the value is set beyond the scope,
    this value will be set as 5 by default, Increases tolerance of
    placing blocks on Datanodes with similar disk space used."
4,hadoop.shell.safely.delete.limit.num.files,100,"Used by -safely option of hadoop fs shell -rm command to avoid
      accidental deletion of large directories. When enabled, the -rm command
      requires confirmation if the number of files to be deleted is greater than
      this limit.  The default limit is 100 files. The warning is disabled if
      the limit is 0 or the -safely is not specified in -rm command."
5,dfs.datanode.data.dir.perm,700,"Permissions for the directories on on the local filesystem where
  the DFS data node store its blocks. The permissions can either be octal or
  symbolic."
6,datanode.https.port,50475,HTTPS port for DataNode.
7,hadoop.security.kms.client.encrypted.key.cache.size,500,Size of the EncryptedKeyVersion cache Queue for each key
8,yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory,10,
9,mapreduce.jobhistory.loadedjobs.cache.size,5,"Size of the loaded job cache.  This property is ignored if
  the property mapreduce.jobhistory.loadedtasks.cache.size is set to a
  positive value."
