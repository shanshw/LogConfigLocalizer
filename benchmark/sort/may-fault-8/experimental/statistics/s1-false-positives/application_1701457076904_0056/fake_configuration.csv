,name,value,description
0,dfs.replication.max,-0.33214396,Maximal block replication.
1,mapreduce.task.combine.progress.records,10000,"The number of records to process during combine output collection
   before sending a progress notification."
2,hadoop.security.crypto.buffer.size,8192,The buffer size used by CryptoInputStream and CryptoOutputStream.
3,yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache,10,
4,mapreduce.reduce.shuffle.fetch.retry.timeout-ms,30000,"Timeout value for fetcher to retry to fetch again when some
  non-fatal failure happens because of some events like NM restart."
5,dfs.replication,3,"Default block replication. 
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time."
6,dfs.client.read.shortcircuit.streams.cache.expiry.ms,300000,"This controls the minimum amount of time
    file descriptors need to sit in the client cache context
    before they can be closed for being inactive for too long."
7,hadoop.security.uid.cache.secs,14400,"This is the config controlling the validity of the entries in the cache
        containing the userId to userName and groupId to groupName used by
        NativeIO getFstat()."
8,dfs.client.test.drop.namenode.response.number,0,"The number of Namenode responses dropped by DFSClient for each RPC call.  Used
    for testing the NN retry cache."
9,mapreduce.shuffle.pathcache.max-weight,10485760,The maximum total weight of entries the cache may contain.
