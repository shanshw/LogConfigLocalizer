,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.datanode.directoryscan.interval,21600,"Interval in seconds for Datanode to scan data directories and
  reconcile the difference between blocks in memory and on the disk.
  Support multiple time unit suffix(case insensitive), as described
  in dfs.heartbeat.interval.If no time unit is specified then seconds
  is assumed."
2,dfs.qjournal.http.read.timeout.ms,60000,"Timeout in milliseconds when reading from a HTTP connection from remote
    journals."
3,dfs.datanode.max.slowdisks.to.exclude,0,"The number of slow disks that needs to be excluded. By default, this parameter is set to 0,
    which disables excluding slow disk when choosing volume."
4,dfs.client-write-packet-size,65536,Packet size for clients to write
5,ipc.ping.interval,60000,"Timeout on waiting response from server, in milliseconds.
  The client will send ping when the interval is passed without receiving bytes,
  if ipc.client.ping is set to true."
6,dfs.datanode.max.nodes.to.report,5,"Number of nodes to include in JSON report. We will return nodes with
    the highest number of votes from peers."
7,yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds,3600,
8,dfs.namenode.snapshot.max.limit,65536,"Limits the maximum number of snapshots allowed per snapshottable
    directory.If the configuration is not set, the default limit
    for maximum no of snapshots allowed is 65536."
9,dfs.block.misreplication.processing.limit,10000,Maximum number of blocks to process for initializing replication queues.
