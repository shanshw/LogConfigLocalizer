,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,ha.failover-controller.cli-check.rpc-timeout.ms,20000,"Timeout that the CLI (manual) FC waits for monitorHealth, getServiceState"
2,yarn.nodemanager.localizer.fetch.thread-count,4,
3,yarn.app.mapreduce.client.job.retry-interval,2000,"The delay between getJob retries in ms for retries configured
  with yarn.app.mapreduce.client.job.max-retries."
4,dfs.client.key.provider.cache.expiry,864000000,DFS client security key cache expiration in milliseconds.
5,dfs.datanode.scan.period.hours,504,"If this is positive, the DataNode will not scan any
        individual block more than once in the specified scan period.
        If this is negative, the block scanner is disabled.
        If this is set to zero, then the default value of 504 hours
        or 3 weeks is used. Prior versions of HDFS incorrectly documented
        that setting this key to zero will disable the block scanner."
6,yarn.nodemanager.container.stderr.tail.bytes,4096,
7,dfs.bytes-per-checksum,512,"The number of bytes per checksum.  Must not be larger than
  dfs.stream-buffer-size"
8,dfs.namenode.fs-limits.max-xattrs-per-inode,32,Maximum number of extended attributes per inode.
9,datanode.https.port,50475,HTTPS port for DataNode.
