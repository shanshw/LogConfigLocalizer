,name,value,description
0,io.bytes.per.checksum,-34591569,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.log-aggregation-status.time-out.ms,600000,
2,dfs.datanode.handler.count,10,The number of server threads for the datanode.
3,dfs.provided.aliasmap.load.retries,0,"The number of retries on the Datanode to load the provided aliasmap;
      defaults to 0."
4,yarn.resourcemanager.admin.client.thread-count,1,
5,yarn.app.mapreduce.am.job.committer.commit-window,10000,"Defines a time window in milliseconds for output commit
  operations.  If contact with the RM has occurred within this window then
  commits are allowed, otherwise the AM will not allow output commits until
  contact with the RM has been re-established."
6,fs.df.interval,60000,Disk usage statistics refresh interval in msec.
7,hadoop.security.group.mapping.ldap.num.attempts.before.failover,3,"This property is the number of attempts to be made for LDAP operations
    using a single LDAP instance. If multiple LDAP servers are configured
    and this number of failed operations is reached, we will switch to the
    next LDAP server. The configuration for the overall number of attempts
    will still be respected, failover will thus be performed only if this
    property is less than hadoop.security.group.mapping.ldap.num.attempts."
8,hadoop.security.kms.client.encrypted.key.cache.num.refill.threads,2,"Number of threads to use for refilling depleted EncryptedKeyVersion
    cache Queues"
9,dfs.image.transfer.bandwidthPerSec,52428800,"Maximum bandwidth used for regular image transfers (instead of
        bootstrapping the standby namenode), in bytes per second.
        This can help keep normal namenode operations responsive during
        checkpointing.
        A default value is 50mb per second.
        The maximum bandwidth used for bootstrapping standby namenode is
        configured with dfs.image.transfer-bootstrap-standby.bandwidthPerSec.
        Support multiple size unit suffix(case insensitive), as described
        in dfs.blocksize."
