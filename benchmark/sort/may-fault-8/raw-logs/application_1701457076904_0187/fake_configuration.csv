,name,value,description
0,io.bytes.per.checksum,-1153021498,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.resourcemanager.scheduler.client.thread-count,50,
2,dfs.datanode.du.reserved,0,"Reserved space in bytes per volume. Always leave this much space free for non dfs use.
      Specific storage type based reservation is also supported. The property can be followed with
      corresponding storage types ([ssd]/[disk]/[archive]/[ram_disk]) for cluster with heterogeneous storage.
      For example, reserved space for RAM_DISK storage can be configured using property
      'dfs.datanode.du.reserved.ram_disk'. If specific storage type reservation is not configured
      then dfs.datanode.du.reserved will be used. Support multiple size unit suffix(case insensitive),
      as described in dfs.blocksize.
      Note: In case of using tune2fs to set reserved-blocks-percentage, or other filesystem tools,
      then you can possibly run into out of disk errors because hadoop will not check those
      external tool configurations."
3,dfs.client.failover.connection.retries.on.timeouts,0,"Expert only. The number of retry attempts a failover IPC client
    will make on socket timeout when establishing a server connection."
4,dfs.qjournal.http.open.timeout.ms,60000,"Timeout in milliseconds when open a new HTTP connection to remote
    journals."
5,ha.health-monitor.sleep-after-disconnect.ms,1000,How long to sleep after an unexpected RPC error.
6,dfs.ha.fencing.ssh.connect-timeout,30000,"SSH connection timeout, in milliseconds, to use with the builtin
    sshfence fencer."
7,dfs.disk.balancer.block.tolerance.percent,10,"When a disk balancer copy operation is proceeding, the datanode is still
      active. So it might not be possible to move the exactly specified
      amount of data. So tolerance allows us to define a percentage which
      defines a good enough move."
8,yarn.app.mapreduce.shuffle.log.limit.kb,0,"Maximum size of the syslog.shuffle file in kilobytes
    (0 for no limit)."
9,dfs.mover.max-no-move-interval,60000,"If this specified amount of time has elapsed and no block has been moved
    out of a source DataNode, on more effort will be made to move blocks out of
    this DataNode in the current Mover iteration."
