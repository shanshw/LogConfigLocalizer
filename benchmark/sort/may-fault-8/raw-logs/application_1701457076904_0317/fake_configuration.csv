,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,mapreduce.shuffle.pathcache.concurrency-level,16,"Uses the concurrency level to create a fixed number of hashtable
    segments, each governed by its own write lock."
2,dfs.disk.balancer.max.disk.errors,5,"During a block move from a source to destination disk, we might
      encounter various errors. This defines how many errors we can tolerate
      before we declare a move between 2 disks (or a step) has failed."
3,dfs.qjournal.finalize-segment.timeout.ms,120000,"Quorum timeout in milliseconds during finalizing for a specific
    segment."
4,seq.io.sort.factor,100,"The number of streams to merge at once while sorting
      files using SequenceFile.Sorter.
      This determines the number of open file handles."
5,yarn.app.attempt.diagnostics.limit.kc,64,
6,dfs.namenode.max.op.size,52428800,Maximum opcode size in bytes.
7,ftp.client-write-packet-size,65536,Packet size for clients to write
8,mapreduce.job.cache.limit.max-single-resource-mb,0,"The maximum size (in MB) of a single resource a map reduce job
    is allow to submit for localization via files, libjars, archives, and
    jobjar command line arguments and through the distributed cache. If set to
    0 the limit is ignored."
9,dfs.client.write.byte-array-manager.count-limit,2048,The maximum number of arrays allowed for each array length.
