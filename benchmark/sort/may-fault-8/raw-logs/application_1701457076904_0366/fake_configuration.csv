,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,io.file.buffer.size,4096,"The size of buffer for use in sequence files.
  The size of this buffer should probably be a multiple of hardware
  page size (4096 on Intel x86), and it determines how much data is
  buffered during read and write operations."
2,mapreduce.client.submit.file.replication,10,"The replication level for submitted job files.  This
  should be around the square root of the number of nodes."
3,dfs.qjournal.new-epoch.timeout.ms,120000,"Timeout in milliseconds when getting an epoch number for write
    access to JournalNodes."
4,yarn.scheduler.configuration.leveldb-store.compaction-interval-secs,86400,
5,hadoop.security.uid.cache.secs,14400,"This is the config controlling the validity of the entries in the cache
        containing the userId to userName and groupId to groupName used by
        NativeIO getFstat()."
6,dfs.namenode.top.num.users,10,Number of top users returned by the top tool
7,dfs.mover.retry.max.attempts,10,"The maximum number of retries before the mover consider the
    move failed."
8,yarn.nm.liveness-monitor.expiry-interval-ms,600000,
9,dfs.ha.tail-edits.period,60,"How often, the StandbyNode and ObserverNode should check if there are new
    edit log entries ready to be consumed. This is the minimum period between
    checking; exponential backoff will be applied if no edits are found and
    dfs.ha.tail-edits.period.backoff-max is configured. By default, no
    backoff is applied.
    Supports multiple time unit suffix (case insensitive), as described
    in dfs.heartbeat.interval."
