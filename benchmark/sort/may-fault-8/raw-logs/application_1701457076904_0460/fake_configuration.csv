,name,value,description
0,io.bytes.per.checksum,-252906185,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.router.interceptor.user.threadpool-size,5,
2,dfs.balancer.service.retries.on.exception,5,"When the balancer is executed as a long-running service, it will retry upon encountering an exception. This
    configuration determines how many times it will retry before considering the exception to be fatal and quitting."
3,dfs.cachereport.intervalMsec,10000,"Determines cache reporting interval in milliseconds.  After this amount of
    time, the DataNode sends a full report of its cache state to the NameNode.
    The NameNode uses the cache report to update its map of cached blocks to
    DataNode locations.

    This configuration has no effect if in-memory caching has been disabled by
    setting dfs.datanode.max.locked.memory to 0 (which is the default).

    If the native libraries are not available to the DataNode, this
    configuration has no effect."
4,yarn.timeline-service.client.fd-clean-interval-secs,60,
5,yarn.resourcemanager.container.liveness-monitor.interval-ms,600000,
6,ipc.[port_number].decay-scheduler.period-ms,5000,"How frequently the decay factor should be applied to the
    operation counts of users. Higher values have less overhead, but respond
    less quickly to changes in client behavior.
    This property applies to DecayRpcScheduler."
7,dfs.datanode.handler.count,10,The number of server threads for the datanode.
8,yarn.nodemanager.container-retry-minimum-interval-ms,1000,
9,dfs.datanode.du.reserved,0,"Reserved space in bytes per volume. Always leave this much space free for non dfs use.
      Specific storage type based reservation is also supported. The property can be followed with
      corresponding storage types ([ssd]/[disk]/[archive]/[ram_disk]) for cluster with heterogeneous storage.
      For example, reserved space for RAM_DISK storage can be configured using property
      'dfs.datanode.du.reserved.ram_disk'. If specific storage type reservation is not configured
      then dfs.datanode.du.reserved will be used. Support multiple size unit suffix(case insensitive),
      as described in dfs.blocksize.
      Note: In case of using tune2fs to set reserved-blocks-percentage, or other filesystem tools,
      then you can possibly run into out of disk errors because hadoop will not check those
      external tool configurations."
