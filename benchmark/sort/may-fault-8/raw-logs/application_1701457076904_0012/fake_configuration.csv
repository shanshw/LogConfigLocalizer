,name,value,description
0,io.bytes.per.checksum,868582317,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.namenode.blockreport.queue.size,1024,The queue size of BlockReportProcessingThread in BlockManager.
2,dfs.edit.log.transfer.bandwidthPerSec,0,"Maximum bandwidth used for transferring edit log to between journal nodes
    for syncing, in bytes per second.
    A default value of 0 indicates that throttling is disabled."
3,yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds,3600,
4,dfs.image.parallel.inode.threshold,1000000,"If the image contains less inodes than this setting, then
        do not write sub-sections and hence disable parallel loading.
        This is because small images load very quickly in serial and
        parallel loading is not needed."
5,mapreduce.reduce.shuffle.fetch.retry.timeout-ms,30000,"Timeout value for fetcher to retry to fetch again when some
  non-fatal failure happens because of some events like NM restart."
6,dfs.journalnode.sync.interval,120000,"Time interval, in milliseconds, between two Journal Node syncs.
    This configuration takes effect only if the journalnode sync is enabled
    by setting the configuration parameter dfs.journalnode.enable.sync to true."
7,dfs.stream-buffer-size,4096,"The size of buffer to stream files.
  The size of this buffer should probably be a multiple of hardware
  page size (4096 on Intel x86), and it determines how much data is
  buffered during read and write operations."
8,mapreduce.job.ubertask.maxreduces,1,"Threshold for number of reduces, beyond which job is considered
  too big for the ubertasking optimization.  CURRENTLY THE CODE CANNOT SUPPORT
  MORE THAN ONE REDUCE and will ignore larger values.  (Zero is a valid max,
  however.)  Users may override this value, but only downward."
9,yarn.timeline-service.flowname.max-size,0,
