,name,value,description
0,io.bytes.per.checksum,1434583012,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,hadoop.security.kms.client.encrypted.key.cache.expiry,43200000,"Cache expiry time for a Key, after which the cache Queue for this
    key will be dropped. Default = 12hrs"
2,io.file.buffer.size,4096,"The size of buffer for use in sequence files.
  The size of this buffer should probably be a multiple of hardware
  page size (4096 on Intel x86), and it determines how much data is
  buffered during read and write operations."
3,dfs.datanode.peer.metrics.min.outlier.detection.samples,1000,"Minimum number of packet send samples which are required to qualify for outlier detection.
      If the number of samples is below this then outlier detection is skipped."
4,yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size,1000,
5,fs.s3a.fast.upload.active.blocks,4,"Maximum Number of blocks a single output stream can have
    active (uploading, or queued to the central FileSystem
    instance's pool of queued operations.

    This stops a single stream overloading the shared thread pool."
6,hadoop.security.groups.cache.secs,300,"This is the config controlling the validity of the entries in the cache
    containing the user->group mapping. When this duration has expired,
    then the implementation of the group mapping provider is invoked to get
    the groups of the user and then cached back."
7,dfs.qjournal.accept-recovery.timeout.ms,120000,"Quorum timeout in milliseconds during accept phase of
    recovery/synchronization for a specific segment."
8,dfs.storage.policy.satisfier.retry.max.attempts,3,"Max retry to satisfy the block storage policy. After this retry block will be removed
    from the movement needed queue."
9,dfs.qjournal.http.read.timeout.ms,60000,"Timeout in milliseconds when reading from a HTTP connection from remote
    journals."
