,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,ipc.[port_number].weighted-cost.handler,1,"The weight multiplier to apply to the time spent in the
    HANDLER phase which do not involve holding a lock.
    See org.apache.hadoop.ipc.ProcessingDetails.Timing for more details on
    this phase. This property applies to WeightedTimeCostProvider."
2,dfs.namenode.snapshot.skiplist.max.levels,0,"Maximum no of the skip levels to be maintained in the skip list for
    storing directory snapshot diffs. By default, it is set to 0 and a linear
    list will be used to store the directory snapshot diffs."
3,mapreduce.job.running.reduce.limit,0,"The maximum number of simultaneous reduce tasks per job.
  There is no limit if this value is 0 or negative."
4,dfs.client.block.write.locateFollowingBlock.retries,5,Number of retries to use when finding the next block during HDFS writes.
5,dfs.webhdfs.netty.low.watermark,32768,Low watermark configuration to Netty for Datanode WebHdfs.
6,dfs.client.deadnode.detection.probe.connection.timeout.ms,20000,Connection timeout for probing dead node in milliseconds.
7,dfs.namenode.lease-hard-limit-sec,1200,Determines the namenode automatic lease recovery interval in seconds.
8,yarn.resourcemanager.delayed.delegation-token.removal-interval-ms,30000,
9,mapreduce.job.maps,2,"The default number of map tasks per job.
  Ignored when mapreduce.framework.name is ""local""."
