EventId,EventTemplate,Occurrences
19b75bb3,Created MRAppMaster for application appattempt_<*>_<*>_<*>,162
b6c60981,Updating Configuration,162
0cd5c477,"Executing with tokens: [Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)]",162
70f56aad,resource-types.xml not found,58
860c743d,Unable to find 'resource-types.xml'.,58
0594ecc2,Using mapred newApiCommitter.,162
c0c8618d,OutputCommitter set in config null,162
9c2ab4d0,"No output committer factory defined, defaulting to FileOutputCommitterFactory",162
24f60e3d,File Output Committer Algorithm version is <*>,162
d1f83c9a,"FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false",162
d79644a2,OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,162
3a2b3aef,Registering class <*> for class <*>,1458
fb1f4268,Default file system [hdfs://2f08f873c798:<*>],486
3a03968c,Emitting job history data to the timeline server is not enabled,162
7a3d0110,Loaded properties from hadoop-metrics2.properties,162
becc4e71,Scheduled Metric snapshot period at <*> second(s).,162
fc657c96,MRAppMaster metrics system started,162
080bfa16,Adding job token for job_<*>_<*> to jobTokenSecretManager,162
f0a11579,Not uberizing job_<*>_<*> because: not enabled; too much RAM;,162
7ee6a6bc,Input size for job job_<*>_<*> = <*>. Number of splits = <*>,162
691cf50f,Number of reduces for job job_<*>_<*> = <*>,162
b348aeef,<*> Transitioned from <*> to <*>,792
8cfccb68,"MRAppMaster launching normal, non-uberized, multi-container job job_<*>_<*>.",162
4800a8aa,"Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: <*>, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.",323
55039769,Listener at <*>,323
70066a26,Starting Socket Reader #<*> for port <*>,322
8c4d0a72,Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server,162
ccc17099,IPC Server Responder: starting,322
73b103d7,IPC Server listener on <*>: starting,322
81b07bff,Instantiated MRClientService at <*>,162
01861b08,Logging initialized <*> to org.eclipse.jetty.util.log.Slf4jLog,162
9c1a3d53,"Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret",162
0859dbfb,Http request log for http.requests.mapreduce is not defined,162
a8927e0e,Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter),162
ae2086c0,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context <*>,324
5ba9445a,Registered webapp guice modules,162
8aa20788,Jetty bound to port <*>,162
e9247c7a,jetty-<*>.<*>.<*>.v20230217; built: <*>-<*>-17T08:<*>:<*>.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm <*>,162
bacbae49,DefaultSessionIdManager workerName=node<*>,162
9ee7bbd8,"No SessionScavenger set, using defaults",162
502523ab,node0 Scavenging every <*>,162
00ac854a,Started <*>,484
3a71660b,Started <*> (http/<*>.<*>)}{<*>},161
0923c3bb,Web app mapreduce started at <*>,161
e79de774,JOB_CREATE job_<*>_<*>,161
8b1732f5,nodeBlacklistingEnabled:true,160
07a75a5d,maxTaskFailuresPerNode is <*>,160
168a0869,blacklistDisablePercent is <*>,160
10c1693b,0% of the mappers will be scheduled using OPPORTUNISTIC containers,160
4ecdc8c5,Connecting to ResourceManager at 2f08f873c798<*>,160
1b9a71a7,"maxContainerCapability: <memory:<*>, vCores:<*>>",160
62365dbe,queue: default,160
293bdc87,Upper limit on the thread pool size is <*>,160
7a27b63d,The thread pool initial size is <*>,160
8825a75c,Processing the event EventType: <*>,350
16c3067a,"Resource capability of task type <*> is set to <memory:<*>, vCores:<*>>",293
d231a1af,task_<*>_<*>_m_<*> Task Transitioned from <*> to <*>,2364
a55d23fc,task_<*>_<*>_r_<*> Task Transitioned from <*> to <*>,389
590bd861,attempt_<*>_<*>_m_<*>_<*> TaskAttempt Transitioned from <*> to <*>,4130
500abf63,attempt_<*>_<*>_r_<*>_<*> TaskAttempt Transitioned from <*> to <*>,773
70768b95,"mapResourceRequest:<memory:<*>, vCores:<*>>",160
10edc0f1,"Event Writer setup for JobId: job_<*>_<*>, File: hdfs://2f08f873c798:<*>/tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>/job_<*>_<*>_<*>.jhist",160
fa3c4543,"reduceResourceRequest:<memory:<*>, vCores:<*>>",133
f3cfcdcd,Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,817
6d3d97fc,"getResources() for application_<*>_<*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*>> knownNMs=<*>",810
e856e146,"Recalculating schedule, headroom=<memory:<*>, vCores:<*>>",789
1fbfd66f,Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>,562
0f71bb1f,Got allocated containers <*>,629
99dd87cd,Assigned container container_<*>_<*>_<*>_<*> to <*>,913
b1bdc9c9,After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,860
c9ebd122,The <*> file on the remote FS is <*>,316
5ad17131,Adding #<*> tokens and #<*> secret keys for NM use for launching container,158
e497a05e,Size of containertokens_dob is <*>,158
944f8887,Putting shuffle token in serviceData,158
36fc78d1,Processing the event EventType: <*> for container container_<*>_<*>_<*>_<*> taskAttempt <*>,1609
df347da1,Launching <*>,913
f4ac93f2,Shuffle port returned by ContainerManager for <*> : <*>,913
97232dd5,TaskAttempt: <*> using containerId: [container_<*>_<*>_<*>_<*> on NM: <*>,913
e215e532,ATTEMPT_START <*>,913
d8c9fc3d,Auth successful for job_<*>_<*> (auth:SIMPLE) from <*> / <*>,911
60675cee,JVM with ID : <*> asked for a task,911
2a1c144a,JVM with ID: <*> given task: <*>,911
b53b8ef4,Progress of TaskAttempt <*> is : <*>.<*>,1814
6995e31f,Done acknowledgment from <*>,907
007ded00,Task succeeded with attempt <*>,907
3a2741bf,Num completed Tasks: <*>,907
ec6b84b4,Reduce slow start threshold reached. Scheduling reduces.,130
1885a18a,"completedMapPercent <*>.<*> totalResourceLimit:<memory:<*>, vCores:<*>> finalMapResourceLimit:<memory:<*>, vCores:<*>> finalReduceResourceLimit:<memory:<*>, vCores:<*>> netScheduledMapResource:<memory:<*>, vCores:<*>> netScheduledReduceResource:<memory:<*>, vCores:<*>>",222
279694a4,Received completed container container_<*>_<*>_<*>_<*>,730
cdaa1ea7,Diagnostics report from attempt_<*>_<*>_m_<*>_<*>:,698
abfa93dd,Ramping up <*>,124
ff65c706,Assigned to reduce,128
f13d7a4d,MapCompletionEvents request from attempt_<*>_<*>_r_<*>_<*>. startIndex <*> maxEvents <*>,128
71c3d1dc,Commit-pending state update from <*>,263
7fa51f52,attempt_<*>_<*>_r_<*>_<*> given a go for committing the task output.,128
3650dc5c,Commit go/no-go request from <*>,263
fe6107f0,Result of canCommit for <*>,263
81e00d20,Calling handler for JobFinishedEvent,155
ad1a35c9,"Job finished cleanly, recording last MRAppMaster retry",155
5735d762,Notify <*> isAMLastRetry: true,310
b2ea851d,RMCommunicator notified that shouldUnregistered is: true,155
b288d94f,JobHistoryEventHandler notified that forceJobCompletion is true,155
2784eb31,Calling stop for all the services,155
c02382a8,Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>,155
c1adc692,Copying <*> to <*>,310
cf0a887f,Copied from: <*> to done location: <*>,310
ca9064ee,Set historyUrl to <*>,155
cced3af1,Moved tmp to done: <*> to <*>,465
6de59625,Stopped JobHistoryEventHandler. super.stop(),155
da04743d,KILLING <*>,216
9ae352d7,Setting job diagnostics to,155
c45e2735,History url is <*>,155
fd178178,Waiting for application to be successfully unregistered.,155
f88b4e72,Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,155
3b7f8573,Deleting staging directory hdfs://2f08f873c798:<*> /tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>,155
fa5d86c2,Stopping server on <*>,309
da6217eb,Stopping IPC Server listener on <*>,309
8429e6cc,Stopping IPC Server Responder,309
f495a4dd,TaskHeartbeatHandler thread interrupted,155
4594e7ea,TaskAttemptFinishingMonitor thread interrupted,155
38c92929,Stopped <*>,308
8ec1e0d8,Stopped <*> (http/<*>.<*>)}{<*>},154
76d635f9,node0 Stopped scavenging,154
e22de8d1,found resource resource-types.xml at file:/usr/local/revisedJQF/v8/hadoop-<*>.<*>.<*>/etc/hadoop/resource-types.xml,104
e38b63ab,attempt_<*>_<*>_m_<*>_<*> given a go for committing the task output.,135
a2f8e5b1,"Cannot assign container Container: [ContainerId: container_<*>_<*>_<*>_<*>, AllocationRequestId: <*>, Version: <*>, NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*> }, ExecutionType: GUARANTEED, ] for a map as either container memory less than required <memory:<*>, vCores:<*>> or no pending map tasks - maps.isEmpty=true",32
958d6e8e,Container complete event for unknown container container_<*>_<*>_<*>_<*>,32
da450fb8,DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_<*>_<*>_m_<*>,35
1c4b924f,Scheduling a redundant attempt for task task_<*>_<*>_m_<*>,35
71478d85,We launched <*> speculations. Sleeping <*> milliseconds.,35
41351536,Issuing kill to other attempt attempt_<*>_<*>_m_<*>_<*>,35
983af3ff,All maps assigned. Ramping up all remaining reduces:<*>,5
72fe13b0,ERROR IN CONTACTING RM.java.io.InterruptedIOException: Call interrupted at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:<*>) at org.apache.hadoop.ipc.Client.call(Client.java:<*>) at org.apache.hadoop.ipc.Client.call(Client.java:<*>) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:<*>) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:<*>) at com.sun.proxy.$Proxy83.allocate(Unknown Source) at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:<*>) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<*>) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<*>) at java.base/java.lang.reflect.Method.invoke(Method.java:<*>) at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:<*>) at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:<*>) at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:<*>) at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:<*>) at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:<*>) at com.sun.proxy.$Proxy84.allocate(Unknown Source) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.makeRemoteRequest(RMContainerRequestor.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$AllocatorRunnable.run(RMCommunicator.java:<*>) at java.base/java.lang.Thread.run(Thread.java:<*>),5
