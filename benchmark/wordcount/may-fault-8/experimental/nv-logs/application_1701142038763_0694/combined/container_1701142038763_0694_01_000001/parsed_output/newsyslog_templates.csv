EventId,EventTemplate,Occurrences
19b75bb3,Created MRAppMaster for application appattempt_<*>_<*>_<*>,1
b6c60981,Updating Configuration,1
0cd5c477,"Executing with tokens: [Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)]",1
e22de8d1,found resource resource-types.xml at file:/usr/local/revisedJQF/v8/hadoop-<*>.<*>.<*>/etc/hadoop/resource-types.xml,1
0594ecc2,Using mapred newApiCommitter.,1
c0c8618d,OutputCommitter set in config null,1
9c2ab4d0,"No output committer factory defined, defaulting to FileOutputCommitterFactory",1
24f60e3d,File Output Committer Algorithm version is <*>,1
d1f83c9a,"FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false",1
d79644a2,OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,1
3a2b3aef,Registering class <*> for class <*>,9
fb1f4268,Default file system [hdfs://2f08f873c798:<*>],3
3a03968c,Emitting job history data to the timeline server is not enabled,1
7a3d0110,Loaded properties from hadoop-metrics2.properties,1
becc4e71,Scheduled Metric snapshot period at <*> second(s).,1
fc657c96,MRAppMaster metrics system started,1
080bfa16,Adding job token for job_<*>_<*> to jobTokenSecretManager,1
1351aab1,Not uberizing job_<*>_<*> because: not enabled; too many maps; too much RAM;,1
7ee6a6bc,Input size for job job_<*>_<*> = <*>. Number of splits = <*>,1
691cf50f,Number of reduces for job job_<*>_<*> = <*>,1
33358c5e,job_<*>_0694Job Transitioned from <*> to <*>,6
8cfccb68,"MRAppMaster launching normal, non-uberized, multi-container job job_<*>_<*>.",1
4800a8aa,"Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: <*>, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.",2
55039769,Listener at <*>,2
70066a26,Starting Socket Reader #<*> for port <*>,2
8c4d0a72,Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server,1
ccc17099,IPC Server Responder: starting,2
73b103d7,IPC Server listener on <*>: starting,2
9c9cab88,Instantiated MRClientService at ed761ad59d44<*>,1
6aa1cf3a,Logging initialized @2307ms to org.eclipse.jetty.util.log.Slf4jLog,1
9c1a3d53,"Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret",1
0859dbfb,Http request log for http.requests.mapreduce is not defined,1
a8927e0e,Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter),1
ae2086c0,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context <*>,2
5ba9445a,Registered webapp guice modules,1
8aa20788,Jetty bound to port <*>,1
64af699d,jetty-<*>.<*>.<*>.v20230217; built: <*>-<*>-17T08:<*>:<*>.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm <*><*>-post-Ubuntu-0ubuntu120.<*>,1
bacbae49,DefaultSessionIdManager workerName=node<*>,1
9ee7bbd8,"No SessionScavenger set, using defaults",1
11ab4b15,node0 Scavenging every 660000ms,1
00ac854a,Started <*>,3
6d472840,"Started ServerConnector@71b6172c{HTTP/<*>.<*>, (http/<*>.<*>)}{<*>}",1
0923c3bb,Web app mapreduce started at <*>,1
e79de774,JOB_CREATE job_<*>_<*>,1
8b1732f5,nodeBlacklistingEnabled:true,1
07a75a5d,maxTaskFailuresPerNode is <*>,1
168a0869,blacklistDisablePercent is <*>,1
10c1693b,0% of the mappers will be scheduled using OPPORTUNISTIC containers,1
4ecdc8c5,Connecting to ResourceManager at 2f08f873c798<*>,1
1b9a71a7,"maxContainerCapability: <memory:<*>, vCores:<*>>",1
62365dbe,queue: default,1
293bdc87,Upper limit on the thread pool size is <*>,1
7a27b63d,The thread pool initial size is <*>,1
8825a75c,Processing the event EventType: <*>,12
16c3067a,"Resource capability of task type <*> is set to <memory:<*>, vCores:<*>>",2
d231a1af,task_<*>_<*>_m_<*> Task Transitioned from <*> to <*>,36
a55d23fc,task_<*>_<*>_r_<*> Task Transitioned from <*> to <*>,3
590bd861,attempt_<*>_<*>_m_<*>_<*> TaskAttempt Transitioned from <*> to <*>,102
500abf63,attempt_<*>_<*>_r_<*>_<*> TaskAttempt Transitioned from <*> to <*>,2
70768b95,"mapResourceRequest:<memory:<*>, vCores:<*>>",1
fa3c4543,"reduceResourceRequest:<memory:<*>, vCores:<*>>",1
10edc0f1,"Event Writer setup for JobId: job_<*>_<*>, File: hdfs://2f08f873c798:<*>/tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>/job_<*>_<*>_<*>.jhist",1
b4e95842,DataStreamer Exceptionjava.lang.IllegalArgumentException: Buffer size <= <*> at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:<*>),1
93eb27d3,Failed to write the job configuration filejava.io.IOException: java.lang.IllegalArgumentException: Buffer size <= <*> at org.apache.hadoop.hdfs.ExceptionLastSeen.set(ExceptionLastSeen.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:<*>) Caused by: java.lang.IllegalArgumentException: Buffer size <= <*> at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:<*>),1
9b0c0891,Error JobHistoryEventHandler in handleEvent: EventType: AM_STARTEDjava.io.IOException: java.lang.IllegalArgumentException: Buffer size <= <*> at org.apache.hadoop.hdfs.ExceptionLastSeen.set(ExceptionLastSeen.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:<*>) Caused by: java.lang.IllegalArgumentException: Buffer size <= <*> at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:<*>),1
496a6d15,"Thread Thread[eventHandlingThread,<*>,main] threw an Exception.org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.io.IOException: java.lang.IllegalArgumentException: Buffer size <= <*> at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$<*>.run(JobHistoryEventHandler.java:<*>) at java.base/java.lang.Thread.run(Thread.java:<*>) Caused by: java.io.IOException: java.lang.IllegalArgumentException: Buffer size <= <*> at org.apache.hadoop.hdfs.ExceptionLastSeen.set(ExceptionLastSeen.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:<*>) Caused by: java.lang.IllegalArgumentException: Buffer size <= <*> at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:<*>)",1
f3cfcdcd,Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,7
6d3d97fc,"getResources() for application_<*>_<*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*>> knownNMs=<*>",14
e856e146,"Recalculating schedule, headroom=<memory:<*>, vCores:<*>>",15
1fbfd66f,Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>,15
0f71bb1f,Got allocated containers <*>,7
f9c99537,Assigned container container_<*>_<*>_<*>_<*> to attempt_<*>_<*>_m_<*>_<*>,21
b1bdc9c9,After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,7
c9ebd122,The <*> file on the remote FS is <*>,2
5ad17131,Adding #<*> tokens and #<*> secret keys for NM use for launching container,1
e497a05e,Size of containertokens_dob is <*>,1
944f8887,Putting shuffle token in serviceData,1
acd0086c,Processing the event EventType: <*> for container container_<*>_<*>_<*>_<*> taskAttempt attempt_<*>_<*>_m_<*>_<*>,39
5f64a848,Launching attempt_<*>_<*>_m_<*>_<*>,21
b088af87,Shuffle port returned by ContainerManager for attempt_<*>_<*>_m_<*>_<*> : <*>,21
f9ac23df,TaskAttempt: [attempt_<*>_<*>_m_<*>_<*>] using containerId: [container_<*>_<*>_<*>_<*> on NM: <*>,21
80625245,ATTEMPT_START task_<*>_<*>_m_<*>,21
d8c9fc3d,Auth successful for job_<*>_<*> (auth:SIMPLE) from <*> / <*>,21
3e0cc33b,JVM with ID : jvm_<*>_<*>_m_<*> asked for a task,21
17ddc538,JVM with ID: jvm_<*>_<*>_m_<*> given task: attempt_<*>_<*>_m_<*>_<*>,21
d5bff8b5,Progress of TaskAttempt attempt_<*>_<*>_m_<*>_<*> is : <*>.<*>,21
294170d5,Task: attempt_<*>_<*>_m_<*>_<*> - exited : java.lang.IllegalArgumentException: Buffer size <= <*> at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:<*>) at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:<*>) at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:<*>) at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:<*>) at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:<*>) at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:<*>) at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.mapred.YarnChild.writeLocalJobFile(YarnChild.java:<*>) at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:<*>) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<*>),21
1394a33b,Diagnostics report from attempt_<*>_<*>_m_<*>_<*>: Error: java.lang.IllegalArgumentException: Buffer size <= <*> at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:<*>) at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:<*>) at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:<*>) at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:<*>) at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:<*>) at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:<*>) at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:<*>) at org.apache.hadoop.mapred.YarnChild.writeLocalJobFile(YarnChild.java:<*>) at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:<*>) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<*>),42
0e4be9d6,<*> failures on node <*>,9
ae71f36c,Added attempt_<*>_<*>_m_<*>_<*> to list of failed maps,20
279694a4,Received completed container container_<*>_<*>_<*>_<*>,18
cdaa1ea7,Diagnostics report from attempt_<*>_<*>_m_<*>_<*>:,18
424f14ec,"attempt_<*>_<*>_m_<*>_<*> transitioned from state FAIL_FINISHING_CONTAINER to FAILED, event type is <*> and <*>",21
99b8a8a2,"Assigning container Container: [ContainerId: container_<*>_<*>_<*>_<*>, AllocationRequestId: <*>, Version: <*>, NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*> }, ExecutionType: GUARANTEED, ] to fast fail map",14
a275647a,Assigned from earlierFailedMaps,14
a0d2d61b,Blacklisted host <*>,3
20ca077e,Update the blacklist for application_<*>_<*>: blacklistAdditions=<*> blacklistRemovals=<*>,2
350cb79a,"Ignore blacklisting set to true. Known: <*>, Blacklisted: <*>, <*>%",1
3a2741bf,Num completed Tasks: <*>,1
db25a59d,Job failed as tasks failed. failedMaps:<*> failedReduces:<*> killedMaps:<*> killedReduces: <*>,1
0ff891cc,Could not deallocate container for task attemptId attempt_<*>_<*>_r_<*>_<*>,1
ad1a35c9,"Job finished cleanly, recording last MRAppMaster retry",1
5735d762,Notify <*> isAMLastRetry: true,2
b2ea851d,RMCommunicator notified that shouldUnregistered is: true,1
b288d94f,JobHistoryEventHandler notified that forceJobCompletion is true,1
2784eb31,Calling stop for all the services,1
c02382a8,Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>,1
6e5e38d1,"In stop, writing event JOB_SUBMITTED",1
22664475,Service <*> failed in state STOPPEDjava.lang.NullPointerException at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>),2
79523fbd,When stopping the service JobHistoryEventHandlerjava.lang.NullPointerException at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>),1
6f60dede,KILLING attempt_<*>_<*>_m_<*>_<*>,3
629ed051,Setting job diagnostics to Task failed task_<*>_<*>_m_000000Job failed as tasks failed. failedMaps:<*> failedReduces:<*> killedMaps:<*> killedReduces: <*>,1
03ca4927,History url is null,1
fd178178,Waiting for application to be successfully unregistered.,1
f88b4e72,Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,1
3b7f8573,Deleting staging directory hdfs://2f08f873c798:<*> /tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>,1
fa5d86c2,Stopping server on <*>,1
da6217eb,Stopping IPC Server listener on <*>,1
8429e6cc,Stopping IPC Server Responder,1
f495a4dd,TaskHeartbeatHandler thread interrupted,1
4594e7ea,TaskAttemptFinishingMonitor thread interrupted,1
9ab47de7,Graceful stop failed. Exiting..java.lang.NullPointerException at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>),1
61bb61d6,Exiting with status <*>: java.lang.NullPointerException,1
