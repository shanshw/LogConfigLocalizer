,name,value,description
0,yarn.app.mapreduce.shuffle.log.backups,5aw7m,"If yarn.app.mapreduce.shuffle.log.limit.kb and
    yarn.app.mapreduce.shuffle.log.backups are greater than zero
    then a ContainerRollngLogAppender is used instead of ContainerLogAppender
    for syslog.shuffle. See
    org.apache.log4j.RollingFileAppender.maxBackupIndex"
1,dfs.datanode.fsdatasetcache.max.threads.per.volume,4,"The maximum number of threads per volume to use for caching new data
    on the datanode. These threads consume both I/O and CPU. This can affect
    normal datanode operations."
2,dfs.image.parallel.threads,4,"The number of threads to use when dfs.image.parallel.load is
        enabled. This setting should be less than
        dfs.image.parallel.target.sections. The optimal number of
        threads will depend on the hardware and environment."
3,dfs.datanode.data.dir.perm,700,"Permissions for the directories on on the local filesystem where
  the DFS data node store its blocks. The permissions can either be octal or
  symbolic."
4,dfs.namenode.replication.work.multiplier.per.iteration,2,"*Note*: Advanced property. Change with caution.
    This determines the total amount of block transfers to begin in
    parallel at a DN, for replication, when such a command list is being
    sent over a DN heartbeat by the NN. The actual number is obtained by
    multiplying this multiplier with the total number of live nodes in the
    cluster. The result number is the number of blocks to begin transfers
    immediately for, per DN heartbeat. This number can be any positive,
    non-zero integer."
5,yarn.timeline-service.writer.async.queue.capacity,100,
6,yarn.router.interceptor.user.threadpool-size,5,
7,ha.health-monitor.sleep-after-disconnect.ms,1000,How long to sleep after an unexpected RPC error.
8,dfs.datanode.max.disks.to.report,5,"Number of disks to include in JSON report per operation. We will return
    disks with the highest latency."
9,hadoop.registry.zk.retry.interval.ms,1000,
