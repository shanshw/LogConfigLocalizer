0,1
7a16ff17,job_<*>_0789Job Transitioned from <*> to <*>
9c9cab88,Instantiated MRClientService at ed761ad59d44<*>
4cc5c6ad,Logging initialized @2478ms to org.eclipse.jetty.util.log.Slf4jLog
64af699d,jetty-<*>.<*>.<*>.v20230217; built: <*>-<*>-17T08:<*>:<*>.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm <*><*>-post-Ubuntu-0ubuntu120.<*>
0fcdc0c2,node0 Scavenging every 600000ms
6d472840,"Started ServerConnector@71b6172c{HTTP/<*>.<*>, (http/<*>.<*>)}{<*>}"
1220eca6,"No ack received, took 23ms (threshold=0ms). File being written: /tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>/job_<*>_<*>_<*>_conf.xml, block: BP-<*>-<*><*>:<*>_<*>, Write pipeline datanodes: [DatanodeInfoWithStorage[<*>,DS-<*>-727f-4efe-8e48-d6b82a66543e,DISK], DatanodeInfoWithStorage[<*>,DS-3dab9923-37b5-4a58-8d6e-a62e3605ce61,DISK], DatanodeInfoWithStorage[<*>,DS-4dcc33ed-f386-<*>-9baf-dd926bab424c,DISK]]."
b3c9c246,Failed to write the job configuration filejava.io.InterruptedIOException: No ack received after 0s and a timeout of 0s at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.setupEventWriter(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$<*>.run(JobHistoryEventHandler.java:<*>) at java.base/java.lang.Thread.run(Thread.java:<*>)
10485bbc,Error JobHistoryEventHandler in handleEvent: EventType: AM_STARTEDjava.io.InterruptedIOException: No ack received after 0s and a timeout of 0s at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.setupEventWriter(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$<*>.run(JobHistoryEventHandler.java:<*>) at java.base/java.lang.Thread.run(Thread.java:<*>)
a67debc8,"Thread Thread[eventHandlingThread,<*>,main] threw an Exception.org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.io.InterruptedIOException: No ack received after 0s and a timeout of 0s at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$<*>.run(JobHistoryEventHandler.java:<*>) at java.base/java.lang.Thread.run(Thread.java:<*>) Caused by: java.io.InterruptedIOException: No ack received after 0s and a timeout of 0s at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.setupEventWriter(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) ... <*> more"
d1df58d8,Done acknowledgment from attempt_<*>_<*>_m_<*>_<*>
1aac72f8,Task succeeded with attempt attempt_<*>_<*>_m_<*>_<*>
f7558028,Diagnostics report from <*>
25e44a77,Task: attempt_<*>_<*>_r_<*>_<*> - exited : java.io.InterruptedIOException: No ack received after 0s and a timeout of 0s at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:<*>) at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:<*>) at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:<*>) at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:<*>) at org.apache.hadoop.mapred.YarnChild$<*>.run(YarnChild.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<*>)
3d61acf1,Diagnostics report from attempt_<*>_<*>_r_<*>_<*>: Error: java.io.InterruptedIOException: No ack received after 0s and a timeout of 0s at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:<*>) at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:<*>) at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.close(TextOutputFormat.java:<*>) at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:<*>) at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:<*>) at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:<*>) at org.apache.hadoop.mapred.YarnChild$<*>.run(YarnChild.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<*>)
0e4be9d6,<*> failures on node <*>
983af3ff,All maps assigned. Ramping up all remaining reduces:<*>
b2abfdcd,"attempt_<*>_<*>_r_<*>_<*> transitioned from state FAIL_FINISHING_CONTAINER to FAILED, event type is <*> and <*>"
db25a59d,Job failed as tasks failed. failedMaps:<*> failedReduces:<*> killedMaps:<*> killedReduces: <*>
6e5e38d1,"In stop, writing event JOB_SUBMITTED"
22664475,Service <*> failed in state STOPPEDjava.lang.NullPointerException at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>)
79523fbd,When stopping the service JobHistoryEventHandlerjava.lang.NullPointerException at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>)
c0ef3cfb,KILLING attempt_<*>_<*>_r_<*>_<*>
092c6e84,Setting job diagnostics to Task failed task_<*>_<*>_r_000000Job failed as tasks failed. failedMaps:<*> failedReduces:<*> killedMaps:<*> killedReduces: <*>
03ca4927,History url is null
9ab47de7,Graceful stop failed. Exiting..java.lang.NullPointerException at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>)
61bb61d6,Exiting with status <*>: java.lang.NullPointerException
