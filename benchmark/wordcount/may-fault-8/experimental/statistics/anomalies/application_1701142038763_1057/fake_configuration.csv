,name,value,description
0,dfs.client.read.shortcircuit.streams.cache.expiry.ms,0,"This controls the minimum amount of time
    file descriptors need to sit in the client cache context
    before they can be closed for being inactive for too long."
1,dfs.datanode.failed.volumes.tolerated,0,"The number of volumes that are allowed to
  fail before a datanode stops offering service. By default
  any volume failure will cause a datanode to shutdown.
  The value should be greater than or equal to -1 , -1 represents minimum
  1 valid volume."
2,mapreduce.reduce.shuffle.fetch.retry.interval-ms,1000,"Time of interval that fetcher retry to fetch again when some
  non-fatal failure happens because of some events like NM restart."
3,dfs.namenode.replication.max-streams-hard-limit,4,Hard limit for all replication streams.
4,mapreduce.client.completion.pollinterval,5000,"The interval (in milliseconds) between which the JobClient
    polls the MapReduce ApplicationMaster for updates about job status. You may want to
    set this to a lower value to make tests run faster on a single node system. Adjusting
    this value in production may lead to unwanted client-server traffic."
5,mapreduce.input.fileinputformat.split.minsize,0,"The minimum size chunk that map input should be split
  into.  Note that some file formats may have minimum split sizes that
  take priority over this setting."
6,hadoop.security.kms.client.timeout,60,"Sets value for KMS client connection timeout, and the read timeout
    to KMS servers."
7,dfs.http.client.retry.max.attempts,10,"Specify the max number of retry attempts for WebHDFS client,
    if the difference between retried attempts and failovered attempts is
    larger than the max number of retry attempts, there will be no more
    retries."
8,yarn.sharedcache.cleaner.period-mins,1440,
9,hadoop.http.authentication.token.validity,36000,"Indicates how long (in seconds) an authentication token is valid before it has
    to be renewed."
