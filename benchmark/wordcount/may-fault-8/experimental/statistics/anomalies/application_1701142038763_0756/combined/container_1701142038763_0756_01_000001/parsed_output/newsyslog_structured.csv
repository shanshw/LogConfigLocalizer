LineId,Date,Time,Pid,Level,Component,Content,EventId,EventTemplate,ParameterList
1,2023-11-29,03:56:48,723,INFO,[main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,Created MRAppMaster for application appattempt_1701142038763_0756_000001,19b75bb3,Created MRAppMaster for application appattempt_<*>_<*>_<*>,"['1701142038763', '0756_000001']"
2,2023-11-29,03:56:48,879,INFO,[main] org.apache.hadoop.security.SecurityUtil,Updating Configuration,b6c60981,Updating Configuration,[]
3,2023-11-29,03:56:48,998,INFO,[main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,"Executing with tokens: [Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 756 cluster_timestamp: 1701142038763 } attemptId: 1 } keyId: -857926061)]",0cd5c477,"Executing with tokens: [Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)]","['756', '1701142038763', '1', '-857926061']"
4,2023-11-29,03:56:49,031,INFO,[main] org.apache.hadoop.conf.Configuration,resource-types.xml not found,70f56aad,resource-types.xml not found,[]
5,2023-11-29,03:56:49,032,INFO,[main] org.apache.hadoop.yarn.util.resource.ResourceUtils,Unable to find 'resource-types.xml'.,860c743d,Unable to find 'resource-types.xml'.,[]
6,2023-11-29,03:56:49,043,INFO,[main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,Using mapred newApiCommitter.,0594ecc2,Using mapred newApiCommitter.,[]
7,2023-11-29,03:56:49,044,INFO,[main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,OutputCommitter set in config null,c0c8618d,OutputCommitter set in config null,[]
8,2023-11-29,03:56:49,075,INFO,[main] org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory,"No output committer factory defined, defaulting to FileOutputCommitterFactory",9c2ab4d0,"No output committer factory defined, defaulting to FileOutputCommitterFactory",[]
9,2023-11-29,03:56:49,076,INFO,[main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,File Output Committer Algorithm version is 2,24f60e3d,File Output Committer Algorithm version is <*>,['2']
10,2023-11-29,03:56:49,077,INFO,[main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,"FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false",d1f83c9a,"FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false",[]
11,2023-11-29,03:56:49,501,INFO,[main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,d79644a2,OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,[]
12,2023-11-29,03:56:49,628,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.jobhistory.EventType', 'org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler']"
13,2023-11-29,03:56:49,628,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType', 'org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher']"
14,2023-11-29,03:56:49,629,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType', 'org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher']"
15,2023-11-29,03:56:49,630,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType', 'org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher']"
16,2023-11-29,03:56:49,630,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType', 'org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler']"
17,2023-11-29,03:56:49,634,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType', 'org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher']"
18,2023-11-29,03:56:49,635,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType', 'org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter']"
19,2023-11-29,03:56:49,635,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType', 'org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter']"
20,2023-11-29,03:56:49,661,INFO,[main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils,Default file system [hdfs://2f08f873c798:9000],fb1f4268,Default file system [hdfs://2f08f873c798:<*>],['9000']
21,2023-11-29,03:56:49,676,INFO,[main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils,Default file system [hdfs://2f08f873c798:9000],fb1f4268,Default file system [hdfs://2f08f873c798:<*>],['9000']
22,2023-11-29,03:56:49,690,INFO,[main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils,Default file system [hdfs://2f08f873c798:9000],fb1f4268,Default file system [hdfs://2f08f873c798:<*>],['9000']
23,2023-11-29,03:56:49,698,INFO,[main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Emitting job history data to the timeline server is not enabled,3a03968c,Emitting job history data to the timeline server is not enabled,[]
24,2023-11-29,03:56:49,734,INFO,[main] org.apache.hadoop.yarn.event.AsyncDispatcher,Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler,3a2b3aef,Registering class <*> for class <*>,"['org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type', 'org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler']"
25,2023-11-29,03:56:49,912,INFO,[main] org.apache.hadoop.metrics2.impl.MetricsConfig,Loaded properties from hadoop-metrics2.properties,7a3d0110,Loaded properties from hadoop-metrics2.properties,[]
26,2023-11-29,03:56:49,982,INFO,[main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl,Scheduled Metric snapshot period at 10 second(s).,becc4e71,Scheduled Metric snapshot period at <*> second(s).,['10']
27,2023-11-29,03:56:49,983,INFO,[main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl,MRAppMaster metrics system started,fc657c96,MRAppMaster metrics system started,[]
28,2023-11-29,03:56:49,989,INFO,[main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl,Adding job token for job_1701142038763_0756 to jobTokenSecretManager,080bfa16,Adding job token for job_<*>_<*> to jobTokenSecretManager,['1701142038763_0756']
29,2023-11-29,03:56:50,100,WARN,[main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl,"Job init failedjava.lang.NumberFormatException: For input string: ""gLKTV""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.base/java.lang.Integer.parseInt(Integer.java:652)
	at java.base/java.lang.Integer.parseInt(Integer.java:770)
	at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:1534)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(JobImpl.java:1250)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.access$3800(JobImpl.java:142)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1497)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1434)
	at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$500(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:493)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1012)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:141)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1544)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1263)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$6.run(MRAppMaster.java:1761)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1757)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1691)
",fcab7c4d,"Job init failedjava.lang.NumberFormatException: For input string: ""gLKTV"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.access$<*>(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory.access$<*>(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$<*>.run(MRAppMaster.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:<*>)","['65', '652', '770', '1534', '1250', '3800', '142', '1497', '1434', '385', '302', '500', '46', '493', '1012', '141', '1544', '1263', '194', '6', '1761', '423', '1899', '1757', '1691']"
30,2023-11-29,03:56:50,102,INFO,[main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,"MRAppMaster launching normal, non-uberized, multi-container job job_1701142038763_0756.",8cfccb68,"MRAppMaster launching normal, non-uberized, multi-container job job_<*>_<*>.",['1701142038763_0756']
31,2023-11-29,03:56:50,131,INFO,[main] org.apache.hadoop.ipc.CallQueueManager,"Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.",4800a8aa,"Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: <*>, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.",['100']
32,2023-11-29,03:56:50,138,INFO,[main] org.apache.hadoop.ipc.Server,Listener at 0.0.0.0:40923,55039769,Listener at <*>,['0.0.0.0:40923']
33,2023-11-29,03:56:50,139,INFO,[Socket Reader #1 for port 0] org.apache.hadoop.ipc.Server,Starting Socket Reader #1 for port 0,70066a26,Starting Socket Reader #<*> for port <*>,"['1', '0']"
34,2023-11-29,03:56:50,334,INFO,[main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl,Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server,8c4d0a72,Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server,[]
35,2023-11-29,03:56:50,335,INFO,[IPC Server listener on 0] org.apache.hadoop.ipc.Server,IPC Server listener on 0: starting,73b103d7,IPC Server listener on <*>: starting,['0']
36,2023-11-29,03:56:50,335,INFO,[IPC Server Responder] org.apache.hadoop.ipc.Server,IPC Server Responder: starting,ccc17099,IPC Server Responder: starting,[]
37,2023-11-29,03:56:50,336,INFO,[main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService,Instantiated MRClientService at cf6e5ca2712c/192.161.20.5:40923,3592ea3d,Instantiated MRClientService at cf6e5ca2712c<*>,['/192.161.20.5:40923']
38,2023-11-29,03:56:50,365,INFO,[main] org.eclipse.jetty.util.log,Logging initialized @2461ms to org.eclipse.jetty.util.log.Slf4jLog,812007f2,Logging initialized @2461ms to org.eclipse.jetty.util.log.Slf4jLog,[]
39,2023-11-29,03:56:50,441,WARN,[main] org.apache.hadoop.security.authentication.server.AuthenticationFilter,"Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret",9c1a3d53,"Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret",[]
40,2023-11-29,03:56:50,444,INFO,[main] org.apache.hadoop.http.HttpRequestLog,Http request log for http.requests.mapreduce is not defined,0859dbfb,Http request log for http.requests.mapreduce is not defined,[]
41,2023-11-29,03:56:50,448,INFO,[main] org.apache.hadoop.http.HttpServer2,Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter),a8927e0e,Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter),[]
42,2023-11-29,03:56:50,474,INFO,[main] org.apache.hadoop.http.HttpServer2,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce,ae2086c0,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context <*>,['mapreduce']
43,2023-11-29,03:56:50,474,INFO,[main] org.apache.hadoop.http.HttpServer2,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static,ae2086c0,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context <*>,['static']
44,2023-11-29,03:56:50,819,INFO,[main] org.apache.hadoop.yarn.webapp.WebApps,Registered webapp guice modules,5ba9445a,Registered webapp guice modules,[]
45,2023-11-29,03:56:50,820,INFO,[main] org.apache.hadoop.http.HttpServer2,Jetty bound to port 38129,8aa20788,Jetty bound to port <*>,['38129']
46,2023-11-29,03:56:50,821,INFO,[main] org.eclipse.jetty.server.Server,jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.20+8-post-Ubuntu-1ubuntu120.04,16a015cc,jetty-<*>.<*>.<*>.v20230217; built: <*>-<*>-17T08:<*>:<*>.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm <*>.<*>.<*>+<*>-post-Ubuntu-1ubuntu120.<*>,"['9', '4.51', '2023-02', '19:37', '11', '0.20+8', '04']"
47,2023-11-29,03:56:50,844,INFO,[main] org.eclipse.jetty.server.session,DefaultSessionIdManager workerName=node0,bacbae49,DefaultSessionIdManager workerName=node<*>,['0']
48,2023-11-29,03:56:50,844,INFO,[main] org.eclipse.jetty.server.session,"No SessionScavenger set, using defaults",9ee7bbd8,"No SessionScavenger set, using defaults",[]
49,2023-11-29,03:56:50,846,INFO,[main] org.eclipse.jetty.server.session,node0 Scavenging every 600000ms,0fcdc0c2,node0 Scavenging every 600000ms,[]
50,2023-11-29,03:56:50,857,INFO,[main] org.eclipse.jetty.server.handler.ContextHandler,"Started o.e.j.s.ServletContextHandler@6cd15072{static,/static,jar:file:/usr/local/revisedJQF/v8/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar!/webapps/static,AVAILABLE}",00ac854a,Started <*>,"['o.e.j.s.ServletContextHandler@6cd15072{static,/static,jar:file:/usr/local/revisedJQF/v8/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar!/webapps/static,AVAILABLE}']"
51,2023-11-29,03:56:51,619,INFO,[main] org.eclipse.jetty.server.handler.ContextHandler,"Started o.e.j.w.WebAppContext@302da330{mapreduce,/,file:///home/hadoop3/hadoop/tmp/nm-local-dir/usercache/root/appcache/application_1701142038763_0756/container_1701142038763_0756_01_000001/tmp/jetty-0_0_0_0-38129-hadoop-yarn-common-3_3_6_jar-_-any-7469874153646984789/webapp/,AVAILABLE}{jar:file:/usr/local/revisedJQF/v8/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar!/webapps/mapreduce}",00ac854a,Started <*>,"['o.e.j.w.WebAppContext@302da330{mapreduce,/,file:///home/hadoop3/hadoop/tmp/nm-local-dir/usercache/root/appcache/application_1701142038763_0756/container_1701142038763_0756_01_000001/tmp/jetty-0_0_0_0-38129-hadoop-yarn-common-3_3_6_jar-_-any-7469874153646984789/webapp/,AVAILABLE}{jar:file:/usr/local/revisedJQF/v8/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar!/webapps/mapreduce}']"
52,2023-11-29,03:56:51,636,INFO,[main] org.eclipse.jetty.server.AbstractConnector,"Started ServerConnector@2eda072{HTTP/1.1, (http/1.1)}{0.0.0.0:38129}",d20658e9,"Started ServerConnector@2eda072{HTTP/<*>.<*>, (http/<*>.<*>)}{<*>}","['1.1', '1.1', '0.0.0.0:38129']"
53,2023-11-29,03:56:51,636,INFO,[main] org.eclipse.jetty.server.Server,Started @3732ms,00ac854a,Started <*>,['@3732ms']
54,2023-11-29,03:56:51,636,INFO,[main] org.apache.hadoop.yarn.webapp.WebApps,Web app mapreduce started at 38129,0923c3bb,Web app mapreduce started at <*>,['38129']
55,2023-11-29,03:56:51,643,INFO,[main] org.apache.hadoop.ipc.CallQueueManager,"Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 3000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.",4800a8aa,"Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: <*>, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.",['3000']
56,2023-11-29,03:56:51,643,INFO,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator,JOB_CREATE job_1701142038763_0756,e79de774,JOB_CREATE job_<*>_<*>,['1701142038763_0756']
57,2023-11-29,03:56:51,643,INFO,[main] org.apache.hadoop.ipc.Server,Listener at 0.0.0.0:40303,55039769,Listener at <*>,['0.0.0.0:40303']
58,2023-11-29,03:56:51,644,INFO,[Socket Reader #1 for port 0] org.apache.hadoop.ipc.Server,Starting Socket Reader #1 for port 0,70066a26,Starting Socket Reader #<*> for port <*>,"['1', '0']"
59,2023-11-29,03:56:51,649,INFO,[IPC Server Responder] org.apache.hadoop.ipc.Server,IPC Server Responder: starting,ccc17099,IPC Server Responder: starting,[]
60,2023-11-29,03:56:51,649,INFO,[IPC Server listener on 0] org.apache.hadoop.ipc.Server,IPC Server listener on 0: starting,73b103d7,IPC Server listener on <*>: starting,['0']
61,2023-11-29,03:56:51,668,INFO,[main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor,nodeBlacklistingEnabled:true,8b1732f5,nodeBlacklistingEnabled:true,[]
62,2023-11-29,03:56:51,668,INFO,[main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor,maxTaskFailuresPerNode is 3,07a75a5d,maxTaskFailuresPerNode is <*>,['3']
63,2023-11-29,03:56:51,668,INFO,[main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor,blacklistDisablePercent is 33,168a0869,blacklistDisablePercent is <*>,['33']
64,2023-11-29,03:56:51,670,INFO,[main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator,0% of the mappers will be scheduled using OPPORTUNISTIC containers,10c1693b,0% of the mappers will be scheduled using OPPORTUNISTIC containers,[]
65,2023-11-29,03:56:51,695,INFO,[main] org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider,Connecting to ResourceManager at 2f08f873c798/192.161.20.17:8030,4ecdc8c5,Connecting to ResourceManager at 2f08f873c798<*>,['/192.161.20.17:8030']
66,2023-11-29,03:56:51,756,INFO,[main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator,"maxContainerCapability: <memory:8192, vCores:4>",1b9a71a7,"maxContainerCapability: <memory:<*>, vCores:<*>>","['8192', '4>']"
67,2023-11-29,03:56:51,756,INFO,[main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator,queue: default,62365dbe,queue: default,[]
68,2023-11-29,03:56:51,760,INFO,[main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl,Upper limit on the thread pool size is 500,293bdc87,Upper limit on the thread pool size is <*>,['500']
69,2023-11-29,03:56:51,760,INFO,[main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl,The thread pool initial size is 10,7a27b63d,The thread pool initial size is <*>,['10']
70,2023-11-29,03:56:51,765,INFO,[main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl,job_1701142038763_0756Job Transitioned from NEW to FAIL_ABORT,67941e17,job_<*>_0756Job Transitioned from <*> to <*>,"['1701142038763', 'NEW', 'FAIL_ABORT']"
71,2023-11-29,03:56:51,770,INFO,[CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler,Processing the event EventType: JOB_ABORT,288b932d,Processing the event EventType: JOB_ABORT,[]
72,2023-11-29,03:56:51,807,INFO,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl,job_1701142038763_0756Job Transitioned from FAIL_ABORT to FAILED,67941e17,job_<*>_0756Job Transitioned from <*> to <*>,"['1701142038763', 'FAIL_ABORT', 'FAILED']"
73,2023-11-29,03:56:51,809,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,"Job finished cleanly, recording last MRAppMaster retry",ad1a35c9,"Job finished cleanly, recording last MRAppMaster retry",[]
74,2023-11-29,03:56:51,810,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,Notify RMCommunicator isAMLastRetry: true,5735d762,Notify <*> isAMLastRetry: true,['RMCommunicator']
75,2023-11-29,03:56:51,810,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator,RMCommunicator notified that shouldUnregistered is: true,b2ea851d,RMCommunicator notified that shouldUnregistered is: true,[]
76,2023-11-29,03:56:51,810,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,Notify JHEH isAMLastRetry: true,5735d762,Notify <*> isAMLastRetry: true,['JHEH']
77,2023-11-29,03:56:51,810,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,JobHistoryEventHandler notified that forceJobCompletion is true,b288d94f,JobHistoryEventHandler notified that forceJobCompletion is true,[]
78,2023-11-29,03:56:51,811,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,Calling stop for all the services,2784eb31,Calling stop for all the services,[]
79,2023-11-29,03:56:51,813,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Stopping JobHistoryEventHandler. Size of the outstanding queue size is 3,c02382a8,Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>,['3']
80,2023-11-29,03:56:51,848,INFO,[eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,"Event Writer setup for JobId: job_1701142038763_0756, File: hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1.jhist",10edc0f1,"Event Writer setup for JobId: job_<*>_<*>, File: hdfs://2f08f873c798:<*>/tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>/job_<*>_<*>_<*>.jhist","['1701142038763_0756', '9000', '1701142038763_0756', '1701142038763', '0756_1']"
81,2023-11-29,03:56:52,041,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,"In stop, writing event JOB_SUBMITTED",4a3798b7,"In stop, writing event <*>",['JOB_SUBMITTED']
82,2023-11-29,03:56:52,043,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,"In stop, writing event JOB_QUEUE_CHANGED",4a3798b7,"In stop, writing event <*>",['JOB_QUEUE_CHANGED']
83,2023-11-29,03:56:52,043,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,"In stop, writing event JOB_FAILED",4a3798b7,"In stop, writing event <*>",['JOB_FAILED']
84,2023-11-29,03:56:52,146,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Copying hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1.jhist to hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756-1701201403199-root-word+count-1701201411789-0-0-FAILED-default-1701201408611.jhist_tmp,c1adc692,Copying <*> to <*>,"['hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1.jhist', 'hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756-1701201403199-root-word+count-1701201411789-0-0-FAILED-default-1701201408611.jhist_tmp']"
85,2023-11-29,03:56:52,190,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Copied from: hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1.jhist to done location: hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756-1701201403199-root-word+count-1701201411789-0-0-FAILED-default-1701201408611.jhist_tmp,cf0a887f,Copied from: <*> to done location: <*>,"['hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1.jhist', 'hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756-1701201403199-root-word+count-1701201411789-0-0-FAILED-default-1701201408611.jhist_tmp']"
86,2023-11-29,03:56:52,191,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Set historyUrl to http://cf6e5ca2712c:19888/jobhistory/job/job_1701142038763_0756,8b21ced7,Set historyUrl to http://cf6e5ca2712c:<*>/jobhistory/job/job_<*>_<*>,"['19888', '1701142038763_0756']"
87,2023-11-29,03:56:52,193,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Copying hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1_conf.xml to hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756_conf.xml_tmp,c1adc692,Copying <*> to <*>,"['hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1_conf.xml', 'hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756_conf.xml_tmp']"
88,2023-11-29,03:56:52,227,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Copied from: hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1_conf.xml to done location: hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756_conf.xml_tmp,cf0a887f,Copied from: <*> to done location: <*>,"['hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756/job_1701142038763_0756_1_conf.xml', 'hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756_conf.xml_tmp']"
89,2023-11-29,03:56:52,233,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Moved tmp to done: hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756.summary_tmp to hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756.summary,cced3af1,Moved tmp to done: <*> to <*>,"['hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756.summary_tmp', 'hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756.summary']"
90,2023-11-29,03:56:52,234,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Moved tmp to done: hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756_conf.xml_tmp to hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756_conf.xml,cced3af1,Moved tmp to done: <*> to <*>,"['hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756_conf.xml_tmp', 'hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756_conf.xml']"
91,2023-11-29,03:56:52,236,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Moved tmp to done: hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756-1701201403199-root-word+count-1701201411789-0-0-FAILED-default-1701201408611.jhist_tmp to hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756-1701201403199-root-word+count-1701201411789-0-0-FAILED-default-1701201408611.jhist,cced3af1,Moved tmp to done: <*> to <*>,"['hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756-1701201403199-root-word+count-1701201411789-0-0-FAILED-default-1701201408611.jhist_tmp', 'hdfs://2f08f873c798:9000/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1701142038763_0756-1701201403199-root-word+count-1701201411789-0-0-FAILED-default-1701201408611.jhist']"
92,2023-11-29,03:56:52,236,INFO,[Thread-71] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler,Stopped JobHistoryEventHandler. super.stop(),6de59625,Stopped JobHistoryEventHandler. super.stop(),[]
93,2023-11-29,03:56:52,241,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator,"Setting job diagnostics to Job init failed : java.lang.NumberFormatException: For input string: ""gLKTV""	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.base/java.lang.Integer.parseInt(Integer.java:652)
	at java.base/java.lang.Integer.parseInt(Integer.java:770)
	at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:1534)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(JobImpl.java:1250)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.access$3800(JobImpl.java:142)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1497)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1434)
	at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$500(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:493)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1012)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:141)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1544)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1263)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$6.run(MRAppMaster.java:1761)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1757)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1691)


",8714635d,"Setting job diagnostics to Job init failed : java.lang.NumberFormatException: For input string: ""gLKTV"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.access$<*>(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory.access$<*>(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$<*>.run(MRAppMaster.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:<*>)",[]
94,2023-11-29,03:56:52,241,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator,History url is http://cf6e5ca2712c:19888/jobhistory/job/job_1701142038763_0756,c2c7d257,History url is http://cf6e5ca2712c:<*>/jobhistory/job/job_<*>_<*>,"['19888', '1701142038763_0756']"
95,2023-11-29,03:56:52,249,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator,Waiting for application to be successfully unregistered.,fd178178,Waiting for application to be successfully unregistered.,[]
96,2023-11-29,03:56:53,252,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator,Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0,f88b4e72,Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,"['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']"
97,2023-11-29,03:56:53,259,INFO,[Thread-71] org.apache.hadoop.mapreduce.v2.app.MRAppMaster,Deleting staging directory hdfs://2f08f873c798:9000 /tmp/hadoop-yarn/staging/root/.staging/job_1701142038763_0756,3b7f8573,Deleting staging directory hdfs://2f08f873c798:<*> /tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>,"['9000', '1701142038763_0756']"
98,2023-11-29,03:56:53,264,INFO,[Thread-71] org.apache.hadoop.ipc.Server,Stopping server on 40303,fa5d86c2,Stopping server on <*>,['40303']
99,2023-11-29,03:56:53,267,INFO,[IPC Server listener on 0] org.apache.hadoop.ipc.Server,Stopping IPC Server listener on 0,da6217eb,Stopping IPC Server listener on <*>,['0']
100,2023-11-29,03:56:53,268,INFO,[IPC Server Responder] org.apache.hadoop.ipc.Server,Stopping IPC Server Responder,8429e6cc,Stopping IPC Server Responder,[]
101,2023-11-29,03:56:53,274,INFO,[TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler,TaskHeartbeatHandler thread interrupted,f495a4dd,TaskHeartbeatHandler thread interrupted,[]
102,2023-11-29,03:56:53,275,INFO,[Ping Checker for TaskAttemptFinishingMonitor] org.apache.hadoop.yarn.util.AbstractLivelinessMonitor,TaskAttemptFinishingMonitor thread interrupted,4594e7ea,TaskAttemptFinishingMonitor thread interrupted,[]
103,2023-11-29,03:56:53,334,WARN,[IPC Server handler 0 on default port 40923] org.apache.hadoop.ipc.Server,"IPC Server handler 0 on default port 40923, call Call#60713 Retry#0 org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB.getTaskAttemptCompletionEvents from 2f08f873c798:41020 / 192.161.20.17:41020java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getTaskAttemptCompletionEvents(JobImpl.java:829)
	at org.apache.hadoop.mapreduce.v2.app.client.MRClientService$MRClientProtocolHandler.getTaskAttemptCompletionEvents(MRClientService.java:292)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBServiceImpl.java:173)
	at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:289)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
",c9458473,"IPC Server handler <*> on default port <*>, call Call#<*> Retry#<*> org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB.getTaskAttemptCompletionEvents from 2f08f873c798:<*> / <*>java.lang.NullPointerException at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getTaskAttemptCompletionEvents(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.client.MRClientService$MRClientProtocolHandler.getTaskAttemptCompletionEvents(MRClientService.java:<*>) at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBServiceImpl.java:<*>) at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$<*>.callBlockingMethod(MRClientProtocol.java:<*>) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:<*>) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:<*>) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:<*>) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:<*>) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:<*>) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:<*>)","['0', '40923', '60713', '0', '41020', '192.161.20.17:41020', '829', '292', '173', '2', '289', '621', '589', '573', '1227', '1094', '1017', '423', '1899', '3048']"
104,2023-11-29,03:56:58,277,INFO,[Thread-71] org.apache.hadoop.ipc.Server,Stopping server on 40923,fa5d86c2,Stopping server on <*>,['40923']
105,2023-11-29,03:56:58,278,INFO,[IPC Server listener on 0] org.apache.hadoop.ipc.Server,Stopping IPC Server listener on 0,da6217eb,Stopping IPC Server listener on <*>,['0']
106,2023-11-29,03:56:58,278,INFO,[IPC Server Responder] org.apache.hadoop.ipc.Server,Stopping IPC Server Responder,8429e6cc,Stopping IPC Server Responder,[]
107,2023-11-29,03:56:58,286,INFO,[Thread-71] org.eclipse.jetty.server.handler.ContextHandler,"Stopped o.e.j.w.WebAppContext@302da330{mapreduce,/,null,STOPPED}{jar:file:/usr/local/revisedJQF/v8/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar!/webapps/mapreduce}",38c92929,Stopped <*>,"['o.e.j.w.WebAppContext@302da330{mapreduce,/,null,STOPPED}{jar:file:/usr/local/revisedJQF/v8/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar!/webapps/mapreduce}']"
108,2023-11-29,03:56:58,296,INFO,[Thread-71] org.eclipse.jetty.server.AbstractConnector,"Stopped ServerConnector@2eda072{HTTP/1.1, (http/1.1)}{0.0.0.0:0}",811b56ab,"Stopped ServerConnector@2eda072{HTTP/<*>.<*>, (http/<*>.<*>)}{<*>}","['1.1', '1.1', '0.0.0.0:0']"
109,2023-11-29,03:56:58,296,INFO,[Thread-71] org.eclipse.jetty.server.session,node0 Stopped scavenging,76d635f9,node0 Stopped scavenging,[]
110,2023-11-29,03:56:58,297,INFO,[Thread-71] org.eclipse.jetty.server.handler.ContextHandler,"Stopped o.e.j.s.ServletContextHandler@6cd15072{static,/static,jar:file:/usr/local/revisedJQF/v8/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar!/webapps/static,STOPPED}",38c92929,Stopped <*>,"['o.e.j.s.ServletContextHandler@6cd15072{static,/static,jar:file:/usr/local/revisedJQF/v8/hadoop-3.3.6/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar!/webapps/static,STOPPED}']"
