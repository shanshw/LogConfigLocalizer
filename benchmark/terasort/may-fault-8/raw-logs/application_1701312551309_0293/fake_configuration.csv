,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.client.write.max-packets-in-flight,80,The maximum number of DFSPackets allowed in flight.
2,dfs.ha.tail-edits.period.backoff-max,0,"The maximum time the tailer should wait between checking for new edit log
    entries. Exponential backoff will be applied when an edit log tail is
    performed but no edits are available to be read. Values less than or
    equal to zero disable backoff entirely; this is the default behavior.
    Supports multiple time unit suffix (case insensitive), as described
    in dfs.heartbeat.interval."
3,nfs.mountd.port,4242,Specify the port number used by Hadoop mount daemon.
4,mapreduce.job.counters.max,120,The max number of user counters allowed per job.
5,nfs.rtmax,1048576,"This is the maximum size in bytes of a READ request
    supported by the NFS gateway. If you change this, make sure you
    also update the nfs mount's rsize(add rsize= # of bytes to the 
    mount directive)."
6,dfs.datanode.restart.replica.expiration,50,"During shutdown for restart, the amount of time in seconds budgeted for
    datanode restart."
7,dfs.namenode.lazypersist.file.scrub.interval.sec,300,"The NameNode periodically scans the namespace for LazyPersist files with
    missing blocks and unlinks them from the namespace. This configuration key
    controls the interval between successive scans. If this value is set to 0,
    the file scrubber is disabled."
8,dfs.datanode.min.outlier.detection.nodes,10,Minimum number of nodes to run outlier detection.
9,yarn.app.mapreduce.shuffle.log.limit.kb,0,"Maximum size of the syslog.shuffle file in kilobytes
    (0 for no limit)."
