,name,value,description
0,io.bytes.per.checksum,-1895087574,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.namenode.safemode.extension,30000,"Determines extension of safe mode in milliseconds after the threshold level
    is reached.  Support multiple time unit suffix (case insensitive), as
    described in dfs.heartbeat.interval."
2,yarn.timeline-service.handler-thread-count,10,
3,dfs.ha.tail-edits.rolledits.timeout,60,The timeout in seconds of calling rollEdits RPC on Active NN.
4,dfs.http.client.retry.max.attempts,10,"Specify the max number of retry attempts for WebHDFS client,
    if the difference between retried attempts and failovered attempts is
    larger than the max number of retry attempts, there will be no more
    retries."
5,dfs.namenode.ec.policies.max.cellsize,4194304,The maximum cell size of erasure coding policy. Default is 4MB.
6,dfs.block.scanner.volume.join.timeout.ms,5000,"The amount of time in milliseconds that the BlockScanner times out waiting
    for the VolumeScanner thread to join during a shutdown call."
7,dfs.balancer.getBlocks.size,2147483648,"Total size in bytes of Datanode blocks to get when fetching a source's
    block list."
8,ipc.ping.interval,60000,"Timeout on waiting response from server, in milliseconds.
  The client will send ping when the interval is passed without receiving bytes,
  if ipc.client.ping is set to true."
9,hadoop.security.uid.cache.secs,14400,"This is the config controlling the validity of the entries in the cache
        containing the userId to userName and groupId to groupName used by
        NativeIO getFstat()."
