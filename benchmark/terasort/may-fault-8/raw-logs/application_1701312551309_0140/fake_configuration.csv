,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,ipc.[port_number].weighted-cost.lockfree,1,"The weight multiplier to apply to the time spent in the
    LOCKFREE phase which do not involve holding a lock.
    See org.apache.hadoop.ipc.ProcessingDetails.Timing for more details on
    this phase. This property applies to WeightedTimeCostProvider."
2,dfs.namenode.retrycache.expirytime.millis,600000,The time for which retry cache entries are retained.
3,fs.s3a.executor.capacity,16,"The maximum number of submitted tasks which is a single
    operation (e.g. rename(), delete()) may submit simultaneously for
    execution -excluding the IO-heavy block uploads, whose capacity
    is set in ""fs.s3a.fast.upload.active.blocks""

    All tasks are submitted to the shared thread pool whose size is
    set in ""fs.s3a.threads.max""; the value of capacity should be less than that
    of the thread pool itself, as the goal is to stop a single operation
    from overloading that thread pool."
4,dfs.balancer.max-no-move-interval,60000,"If this specified amount of time has elapsed and no block has been moved
    out of a source DataNode, on more effort will be made to move blocks out of
    this DataNode in the current Balancer iteration."
5,nfs.wtmax,1048576,"This is the maximum size in bytes of a WRITE request
    supported by the NFS gateway. If you change this, make sure you
    also update the nfs mount's wsize(add wsize= # of bytes to the 
    mount directive)."
6,ftp.blocksize,67108864,Block size
7,yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms,20,
8,dfs.datanode.ec.reconstruction.stripedread.buffer.size,65536,Datanode striped read buffer size.
9,dfs.namenode.list.cache.directives.num.responses,100,"This value controls the number of cache directives that the NameNode will
    send over the wire in response to a listDirectives RPC."
