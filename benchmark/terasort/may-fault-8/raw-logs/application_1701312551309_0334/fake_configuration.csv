,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.resourcemanager.delegation.key.update-interval,86400000,
2,mapreduce.job.ubertask.maxreduces,1,"Threshold for number of reduces, beyond which job is considered
  too big for the ubertasking optimization.  CURRENTLY THE CODE CANNOT SUPPORT
  MORE THAN ONE REDUCE and will ignore larger values.  (Zero is a valid max,
  however.)  Users may override this value, but only downward."
3,hadoop.zk.retry-interval-ms,1000,Retry interval in milliseconds when connecting to ZooKeeper.
4,dfs.client.write.byte-array-manager.count-limit,2048,The maximum number of arrays allowed for each array length.
5,dfs.client.write.max-packets-in-flight,80,The maximum number of DFSPackets allowed in flight.
6,yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs,3600,
7,ipc.[port_number].decay-scheduler.period-ms,5000,"How frequently the decay factor should be applied to the
    operation counts of users. Higher values have less overhead, but respond
    less quickly to changes in client behavior.
    This property applies to DecayRpcScheduler."
8,dfs.namenode.max.slowpeer.collect.nodes,5,"How many slow nodes we will collect for filtering out
    when choosing targets for blocks.

    It is ignored if dfs.namenode.block-placement-policy.exclude-slow-nodes.enabled is false."
9,dfs.datanode.max.slowdisks.to.exclude,0,"The number of slow disks that needs to be excluded. By default, this parameter is set to 0,
    which disables excluding slow disk when choosing volume."
