,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size,10000,
2,dfs.namenode.checkpoint.check.period,60,"The SecondaryNameNode and CheckpointNode will poll the NameNode
  every 'dfs.namenode.checkpoint.check.period' seconds to query the number
  of uncheckpointed transactions. Support multiple time unit suffix(case insensitive),
  as described in dfs.heartbeat.interval.If no time unit is specified then
  seconds is assumed."
3,dfs.image.parallel.inode.threshold,1000000,"If the image contains less inodes than this setting, then
        do not write sub-sections and hence disable parallel loading.
        This is because small images load very quickly in serial and
        parallel loading is not needed."
4,yarn.nodemanager.container.stderr.tail.bytes,4096,
5,mapreduce.job.end-notification.retry.interval,1000,"The number of milliseconds the submitter of the job wants to
    wait before job end notification is retried if it fails. This is capped by
    mapreduce.job.end-notification.max.retry.interval"
6,yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms,1000,
7,dfs.replication.max,512,Maximal block replication.
8,dfs.datanode.readahead.bytes,4194304,"While reading block files, if the Hadoop native libraries are available,
        the datanode can use the posix_fadvise system call to explicitly
        page data into the operating system buffer cache ahead of the current
        reader's position. This can improve performance especially when
        disks are highly contended.

        This configuration specifies the number of bytes ahead of the current
        read position which the datanode will attempt to read ahead. This
        feature may be disabled by configuring this property to 0.

        If the native libraries are not available, this configuration has no
        effect."
9,dfs.client-write-packet-size,65536,Packet size for clients to write
