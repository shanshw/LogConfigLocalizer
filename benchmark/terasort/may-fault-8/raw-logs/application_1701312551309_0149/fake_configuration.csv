,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.nodemanager.container-diagnostics-maximum-size,10000,
2,yarn.app.mapreduce.am.hard-kill-timeout-ms,10000,Number of milliseconds to wait before the job client kills the application.
3,dfs.datanode.readahead.bytes,4194304,"While reading block files, if the Hadoop native libraries are available,
        the datanode can use the posix_fadvise system call to explicitly
        page data into the operating system buffer cache ahead of the current
        reader's position. This can improve performance especially when
        disks are highly contended.

        This configuration specifies the number of bytes ahead of the current
        read position which the datanode will attempt to read ahead. This
        feature may be disabled by configuring this property to 0.

        If the native libraries are not available, this configuration has no
        effect."
4,dfs.namenode.snapshotdiff.listing.limit,1000,"Limit the number of entries generated by getSnapshotDiffReportListing within
    one rpc call to the namenode.If less or equal to zero, at most
    DFS_NAMENODE_SNAPSHOT_DIFF_LISTING_LIMIT_DEFAULT (= 1000) will be sent
    across to the client within one rpc call."
5,dfs.client.block.write.replace-datanode-on-failure.min-replication,0,"The minimum number of replications that are needed to not to fail
      the write pipeline if new datanodes can not be found to replace
      failed datanodes (could be due to network failure) in the write pipeline.
      If the number of the remaining datanodes in the write pipeline is greater
      than or equal to this property value, continue writing to the remaining nodes.
      Otherwise throw exception.

      If this is set to 0, an exception will be thrown, when a replacement
      can not be found.
      See also dfs.client.block.write.replace-datanode-on-failure.policy"
6,dfs.blockreport.incremental.intervalMsec,0,"If set to a positive integer, the value in ms to wait between sending
    incremental block reports from the Datanode to the Namenode."
7,mapreduce.job.running.reduce.limit,0,"The maximum number of simultaneous reduce tasks per job.
  There is no limit if this value is 0 or negative."
8,dfs.webhdfs.ugi.expire.after.access,600000,"How long in milliseconds after the last access
      the cached UGI will expire. With 0, never expire."
9,dfs.namenode.delegation.token.renew-interval,86400000,The renewal interval for delegation token in milliseconds.
