,name,value,description
0,mapreduce.jobhistory.intermediate-user-done-dir.permissions,-0.2599095,"The permissions of the user directories in
  ${mapreduce.jobhistory.intermediate-done-dir}. The user and the group
  permission must be 7, this is enforced."
1,dfs.namenode.path.based.cache.retry.interval.ms,30000,"When the NameNode needs to uncache something that is cached, or cache
    something that is not cached, it must direct the DataNodes to do so by
    sending a DNA_CACHE or DNA_UNCACHE command in response to a DataNode
    heartbeat.  This parameter controls how frequently the NameNode will
    resend these commands."
2,io.seqfile.compress.blocksize,1000000,"The minimum block size for compression in block compressed
          SequenceFiles."
3,yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb,0,
4,dfs.qjournal.accept-recovery.timeout.ms,120000,"Quorum timeout in milliseconds during accept phase of
    recovery/synchronization for a specific segment."
5,mapreduce.job.reducer.unconditional-preempt.delay.sec,300,"The threshold (in seconds) after which an unsatisfied
      mapper request triggers a forced reducer preemption irrespective of the
      anticipated headroom. By default, it is set to 5 mins. Setting it to 0
      leads to immediate reducer preemption. Setting to -1 disables this
      preemption altogether."
6,dfs.namenode.checkpoint.max-retries,3,"The SecondaryNameNode retries failed checkpointing. If the 
  failure occurs while loading fsimage or replaying edits, the number of
  retries is limited by this variable."
7,dfs.namenode.replication.work.multiplier.per.iteration,2,"*Note*: Advanced property. Change with caution.
    This determines the total amount of block transfers to begin in
    parallel at a DN, for replication, when such a command list is being
    sent over a DN heartbeat by the NN. The actual number is obtained by
    multiplying this multiplier with the total number of live nodes in the
    cluster. The result number is the number of blocks to begin transfers
    immediately for, per DN heartbeat. This number can be any positive,
    non-zero integer."
8,yarn.app.mapreduce.client.job.max-retries,3,"The number of retries the client will make for getJob and
    dependent calls.
    This is needed for non-HDFS DFS where additional, high level
    retries are required to avoid spurious failures during the getJob call.
    30 is a good value for WASB"
9,mapreduce.job.speculative.retry-after-no-speculate,1000,"The waiting time(ms) to do next round of speculation
  if there is no task speculated in this round."
