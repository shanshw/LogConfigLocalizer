,name,value,description
0,io.bytes.per.checksum,-41898224,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,hadoop.security.kms.client.encrypted.key.cache.expiry,43200000,"Cache expiry time for a Key, after which the cache Queue for this
    key will be dropped. Default = 12hrs"
2,fs.s3a.connection.timeout,200000,Socket connection timeout in milliseconds.
3,dfs.provided.aliasmap.load.retries,0,"The number of retries on the Datanode to load the provided aliasmap;
      defaults to 0."
4,dfs.datanode.directoryscan.throttle.limit.ms.per.sec,1000,"The report compilation threads are limited to only running for
  a given number of milliseconds per second, as configured by the
  property. The limit is taken per thread, not in aggregate, e.g. setting
  a limit of 100ms for 4 compiler threads will result in each thread being
  limited to 100ms, not 25ms.

  Note that the throttle does not interrupt the report compiler threads, so the
  actual running time of the threads per second will typically be somewhat
  higher than the throttle limit, usually by no more than 20%.

  Setting this limit to 1000 disables compiler thread throttling. Only
  values between 1 and 1000 are valid. Setting an invalid value will result
  in the throttle being disabled and an error message being logged. 1000 is
  the default setting."
5,dfs.namenode.ec.policies.max.cellsize,4194304,The maximum cell size of erasure coding policy. Default is 4MB.
6,yarn.app.mapreduce.client.job.retry-interval,2000,"The delay between getJob retries in ms for retries configured
  with yarn.app.mapreduce.client.job.max-retries."
7,dfs.namenode.redundancy.queue.restart.iterations,2400,"When picking blocks from the low redundancy queues, reset the
    bookmarked iterator after the set number of iterations to ensure any blocks
    which were not processed on the first pass are retried before the iterators
    would naturally reach their end point. This ensures blocks are retried
    more frequently when there are many pending blocks or blocks are
    continuously added to the queues preventing the iterator reaching its
    natural endpoint.
    The default setting of 2400 combined with the default of
    dfs.namenode.redundancy.interval.seconds means the iterators will be reset
    approximately every 2 hours.
    Setting this parameter to zero disables the feature and the iterators will
    be reset only when the end of all queues has been reached."
8,dfs.block.scanner.volume.bytes.per.second,1048576,"If this is configured less than or equal to zero, the DataNode's block scanner will be disabled.  If this
        is positive, this is the number of bytes per second that the DataNode's
        block scanner will try to scan from each volume."
9,yarn.resourcemanager.leveldb-state-store.compaction-interval-secs,3600,
