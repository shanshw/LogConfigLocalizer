,name,value,description
0,mapreduce.fileoutputcommitter.algorithm.version,-93244609,"The file output committer algorithm version
  valid algorithm version number: 1 or 2
  default to 2, which is the original algorithm

  In algorithm version 1,

  1. commitTask will rename directory
  $joboutput/_temporary/$appAttemptID/_temporary/$taskAttemptID/
  to
  $joboutput/_temporary/$appAttemptID/$taskID/

  2. recoverTask will also do a rename
  $joboutput/_temporary/$appAttemptID/$taskID/
  to
  $joboutput/_temporary/($appAttemptID + 1)/$taskID/

  3. commitJob will merge every task output file in
  $joboutput/_temporary/$appAttemptID/$taskID/
  to
  $joboutput/, then it will delete $joboutput/_temporary/
  and write $joboutput/_SUCCESS

  It has a performance regression, which is discussed in MAPREDUCE-4815.
  If a job generates many files to commit then the commitJob
  method call at the end of the job can take minutes.
  the commit is single-threaded and waits until all
  tasks have completed before commencing.

  algorithm version 2 will change the behavior of commitTask,
  recoverTask, and commitJob.

  1. commitTask will rename all files in
  $joboutput/_temporary/$appAttemptID/_temporary/$taskAttemptID/
  to $joboutput/

  2. recoverTask actually doesn't require to do anything, but for
  upgrade from version 1 to version 2 case, it will check if there
  are any files in
  $joboutput/_temporary/($appAttemptID - 1)/$taskID/
  and rename them to $joboutput/

  3. commitJob can simply delete $joboutput/_temporary and write
  $joboutput/_SUCCESS

  This algorithm will reduce the output commit time for
  large jobs by having the tasks commit directly to the final
  output directory as they were completing and commitJob had
  very little to do."
1,mapreduce.job.speculative.retry-after-no-speculate,1000,"The waiting time(ms) to do next round of speculation
  if there is no task speculated in this round."
2,dfs.namenode.replication.min,1,Minimal block replication.
3,yarn.timeline-service.generic-application-history.max-applications,10000,
4,dfs.namenode.blockreport.max.lock.hold.time,4,The BlockReportProcessingThread max write lock hold time in ms.
5,ipc.server.listen.queue.size,256,"Indicates the length of the listen queue for servers accepting
               client connections."
6,yarn.app.mapreduce.task.container.log.backups,0,"Number of backup files for task logs when using
    ContainerRollingLogAppender (CRLA). See
    org.apache.log4j.RollingFileAppender.maxBackupIndex. By default,
    ContainerLogAppender (CLA) is used, and container logs are not rolled. CRLA
    is enabled for tasks when both mapreduce.task.userlog.limit.kb and
    yarn.app.mapreduce.task.container.log.backups are greater than zero."
7,dfs.namenode.maintenance.replication.min,1,Minimal live block replication in existence of maintenance mode.
8,dfs.client.hedged.read.threadpool.size,0,"Support 'hedged' reads in DFSClient. To enable this feature, set the parameter
    to a positive number. The threadpool size is how many threads to dedicate
    to the running of these 'hedged', concurrent reads in your client."
9,dfs.client.deadnode.detection.probe.deadnode.interval.ms,60000,Interval time in milliseconds for probing dead node behavior.
