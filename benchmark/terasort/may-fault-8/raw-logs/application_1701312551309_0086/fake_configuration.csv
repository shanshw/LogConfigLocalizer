,name,value,description
0,io.bytes.per.checksum,1954044886,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min,3600,
2,mapreduce.job.ubertask.maxreduces,1,"Threshold for number of reduces, beyond which job is considered
  too big for the ubertasking optimization.  CURRENTLY THE CODE CANNOT SUPPORT
  MORE THAN ONE REDUCE and will ignore larger values.  (Zero is a valid max,
  however.)  Users may override this value, but only downward."
3,dfs.namenode.ec.policies.max.cellsize,4194304,The maximum cell size of erasure coding policy. Default is 4MB.
4,dfs.stream-buffer-size,4096,"The size of buffer to stream files.
  The size of this buffer should probably be a multiple of hardware
  page size (4096 on Intel x86), and it determines how much data is
  buffered during read and write operations."
5,dfs.datanode.ec.reconstruction.stripedread.buffer.size,65536,Datanode striped read buffer size.
6,yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs,86400,
7,dfs.namenode.accesstime.precision,3600000,"The access time for HDFS file is precise upto this value. 
               The default value is 1 hour. Setting a value of 0 disables
               access times for HDFS."
8,dfs.namenode.fs-limits.min-block-size,1048576,"Minimum block size in bytes, enforced by the Namenode at create
      time. This prevents the accidental creation of files with tiny block
      sizes (and thus many blocks), which can degrade performance. Support multiple
      size unit suffix(case insensitive), as described in dfs.blocksize."
9,fs.du.interval,600000,File space usage statistics refresh interval in msec.
