,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.client.failover-retries-on-socket-timeouts,0,
2,hadoop.shell.safely.delete.limit.num.files,100,"Used by -safely option of hadoop fs shell -rm command to avoid
      accidental deletion of large directories. When enabled, the -rm command
      requires confirmation if the number of files to be deleted is greater than
      this limit.  The default limit is 100 files. The warning is disabled if
      the limit is 0 or the -safely is not specified in -rm command."
3,mapreduce.reduce.shuffle.retry-delay.max.ms,60000,"The maximum number of ms the reducer will delay before retrying
  to download map data."
4,yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs,20,
5,dfs.namenode.blocks.per.postponedblocks.rescan,10000,"Number of blocks to rescan for each iteration of
    postponedMisreplicatedBlocks."
6,yarn.router.pipeline.cache-max-size,25,
7,dfs.mover.max-no-move-interval,60000,"If this specified amount of time has elapsed and no block has been moved
    out of a source DataNode, on more effort will be made to move blocks out of
    this DataNode in the current Mover iteration."
8,mapreduce.job.running.map.limit,0,"The maximum number of simultaneous map tasks per job.
  There is no limit if this value is 0 or negative."
9,yarn.app.mapreduce.am.job.committer.cancel-timeout,60000,"The amount of time in milliseconds to wait for the output
    committer to cancel an operation if the job is killed"
