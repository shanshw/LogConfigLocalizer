,name,value,description
0,hadoop.security.dns.log-slow-lookups.threshold.ms,OzsiE,"If slow lookup logging is enabled, this threshold is used to decide if a
    lookup is considered slow enough to be logged."
1,mapreduce.job.ubertask.maxreduces,1,"Threshold for number of reduces, beyond which job is considered
  too big for the ubertasking optimization.  CURRENTLY THE CODE CANNOT SUPPORT
  MORE THAN ONE REDUCE and will ignore larger values.  (Zero is a valid max,
  however.)  Users may override this value, but only downward."
2,yarn.scheduler.configuration.max.version,100,
3,yarn.nodemanager.log.retain-seconds,10800,
4,dfs.datanode.max.locked.memory,0,"The amount of memory in bytes to use for caching of block replicas in
    memory on the datanode. The datanode's maximum locked memory soft ulimit
    (RLIMIT_MEMLOCK) must be set to at least this value, else the datanode
    will abort on startup. Support multiple size unit suffix(case insensitive),
    as described in dfs.blocksize.

    By default, this parameter is set to 0, which disables in-memory caching.

    If the native libraries are not available to the DataNode, this
    configuration has no effect."
5,dfs.namenode.decommission.backoff.monitor.pending.blocks.per.lock,1000,"When loading blocks into the replication queue, release the namenode write
    lock after the defined number of blocks have been processed."
6,fs.s3a.paging.maximum,5000,"How many keys to request from S3 when doing
     directory listings at a time."
7,dfs.encrypt.data.transfer.cipher.key.bitlength,128,"The key bitlength negotiated by dfsclient and datanode for encryption.
    This value may be set to either 128, 192 or 256."
8,yarn.nodemanager.local-cache.max-files-per-directory,8192,
9,yarn.sharedcache.store.in-memory.staleness-period-mins,10080,
