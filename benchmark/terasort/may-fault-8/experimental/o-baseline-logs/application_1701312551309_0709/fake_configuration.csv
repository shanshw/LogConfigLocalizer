,name,value,description
0,io.bytes.per.checksum,-2001296879,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,mapreduce.reduce.shuffle.connect.timeout,180000,"Expert: The maximum amount of time (in milli seconds) reduce
  task spends in trying to connect to a remote node for getting map output."
2,dfs.datanode.ec.reconstruction.threads,8,"Number of threads used by the Datanode for background
    reconstruction work."
3,dfs.blockreport.intervalMsec,21600000,Determines block reporting interval in milliseconds.
4,dfs.datanode.socket.reuse.keepalive,4000,"The window of time in ms before the DataXceiver closes a socket for a
    single request.  If a second request occurs within that window, the
    socket can be reused."
5,dfs.namenode.file.close.num-committed-allowed,0,"Normally a file can only be closed with all its blocks are committed.
    When this value is set to a positive integer N, a file can be closed
    when N blocks are committed and the rest complete."
6,fs.s3a.attempts.maximum,20,How many times we should retry commands on transient errors.
7,hadoop.registry.zk.connection.timeout.ms,15000,Zookeeper connection timeout in milliseconds
8,dfs.balancer.max-no-move-interval,60000,"If this specified amount of time has elapsed and no block has been moved
    out of a source DataNode, on more effort will be made to move blocks out of
    this DataNode in the current Balancer iteration."
9,dfs.namenode.reconstruction.pending.timeout-sec,300,"Timeout in seconds for block reconstruction.  If this value is 0 or less,
    then it will default to 5 minutes."
