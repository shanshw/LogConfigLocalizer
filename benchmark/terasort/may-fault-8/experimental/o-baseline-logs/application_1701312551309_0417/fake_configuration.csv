,name,value,description
0,io.bytes.per.checksum,367932490,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,fs.s3a.retry.limit,7,"Number of times to retry any repeatable S3 client request on failure,
    excluding throttling requests."
2,dfs.datanode.slowdisk.low.threshold.ms,20,Threshold in milliseconds below which a disk is definitely not slow.
3,dfs.namenode.snapshot.max.limit,65536,"Limits the maximum number of snapshots allowed per snapshottable
    directory.If the configuration is not set, the default limit
    for maximum no of snapshots allowed is 65536."
4,yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size,10,
5,dfs.datanode.network.counts.cache.max.size,2147483647,"The maximum number of entries the datanode per-host network error
    count cache may contain."
6,mapreduce.shuffle.max.connections,0,"Max allowed connections for the shuffle.  Set to 0 (zero)
               to indicate no limit on the number of connections."
7,dfs.client.failover.max.attempts,15,"Expert only. The number of client failover attempts that should be
    made before the failover is considered failed."
8,mapreduce.shuffle.max.threads,0,"Max allowed threads for serving shuffle connections. Set to zero
  to indicate the default of 2 times the number of available
  processors (as reported by Runtime.availableProcessors()). Netty is used to
  serve requests, so a thread is not needed for each connection."
9,hadoop.security.groups.cache.warn.after.ms,5000,"If looking up a single user to group takes longer than this amount of
    milliseconds, we will log a warning message."
