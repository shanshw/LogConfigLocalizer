,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,hadoop.shell.safely.delete.limit.num.files,100,"Used by -safely option of hadoop fs shell -rm command to avoid
      accidental deletion of large directories. When enabled, the -rm command
      requires confirmation if the number of files to be deleted is greater than
      this limit.  The default limit is 100 files. The warning is disabled if
      the limit is 0 or the -safely is not specified in -rm command."
2,yarn.client.nodemanager-client-async.thread-pool-max-size,500,
3,mapreduce.job.cache.limit.max-resources-mb,0,"The maximum size (in MB) a map reduce job is allowed to submit
    for localization via files, libjars, archives, and jobjar command line
    arguments and through the distributed cache. If set to 0 the limit is
    ignored."
4,dfs.client.max.block.acquire.failures,3,Maximum failures allowed when trying to get block information from a specific datanode.
5,dfs.client.write.byte-array-manager.count-reset-time-period-ms,10000,"The time period in milliseconds that the allocation count for each array length is
    reset to zero if there is no increment."
6,dfs.balancer.max-iteration-time,1200000,"Maximum amount of time while an iteration can be run by the Balancer. After
    this time the Balancer will stop the iteration, and reevaluate the work
    needs to be done to Balance the cluster. The default value is 20 minutes."
7,yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds,60,
8,nfs.wtmax,1048576,"This is the maximum size in bytes of a WRITE request
    supported by the NFS gateway. If you change this, make sure you
    also update the nfs mount's wsize(add wsize= # of bytes to the 
    mount directive)."
9,net.topology.script.number.args,100,"The max number of args that the script configured with
    net.topology.script.file.name should be run with. Each arg is an
    IP address."
