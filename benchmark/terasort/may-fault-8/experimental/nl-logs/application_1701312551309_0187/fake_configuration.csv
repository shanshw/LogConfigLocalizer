,name,value,description
0,io.bytes.per.checksum,340986209,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.replication,3,"Default block replication. 
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time."
2,dfs.client.deadnode.detection.rpc.threads,20,The maximum number of threads to use for calling RPC call to recheck the liveness of dead node.
3,dfs.client.cached.conn.retry,3,"The number of times the HDFS client will pull a socket from the
   cache.  Once this number is exceeded, the client will try to create a new
   socket."
4,dfs.client.short.circuit.num,1,"Number of short-circuit caches. This setting should
    be in the range 1 - 5. Lower values will result in lower CPU consumption; higher
    values may speed up massive parallel reading files."
5,yarn.nodemanager.node-labels.resync-interval-ms,120000,
6,ipc.maximum.data.length,134217728,"This indicates the maximum IPC message length (bytes) that can be
    accepted by the server. Messages larger than this value are rejected by the
    immediately to avoid possible OOMs. This setting should rarely need to be
    changed."
7,mapreduce.jobhistory.max-age-ms,604800000,"Job history files older than this many milliseconds will
  be deleted when the history cleaner runs. Defaults to 604800000 (1 week)."
8,yarn.nodemanager.resource.percentage-physical-cpu-limit,100,
9,mapreduce.input.fileinputformat.list-status.num-threads,1,"The number of threads to use to list and fetch block locations
  for the specified input paths. Note: multiple threads should not be used
  if a custom non thread-safe path filter is used."
