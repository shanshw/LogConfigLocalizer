,name,value,description
0,io.bytes.per.checksum,-806796055,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs,86400,
2,yarn.resourcemanager.epoch.range,0,
3,mapreduce.job.encrypted-intermediate-data-key-size-bits,128,Mapreduce encrypt data key size default is 128
4,dfs.namenode.get-blocks.max-qps,20,"The maximum number of getBlocks RPCs data movement utilities can make to
    a NameNode per second. Values less than or equal to 0 disable throttling.
    This affects anything that uses a NameNodeConnector, i.e., the Balancer,
    Mover, and StoragePolicySatisfier."
5,hadoop.registry.zk.retry.ceiling.ms,60000,"Zookeeper retry limit in milliseconds, during
      exponential backoff.

      This places a limit even
      if the retry times and interval limit, combined
      with the backoff policy, result in a long retry
      period"
6,fs.s3a.list.version,2,"Select which version of the S3 SDK's List Objects API to use.  Currently
    support 2 (default) and 1 (older API)."
7,mapreduce.shuffle.listen.queue.size,128,The length of the shuffle server listen queue.
8,dfs.namenode.max-num-blocks-to-log,1000,"Puts a limit on the number of blocks printed to the log by the Namenode
    after a block report."
9,nfs.wtmax,1048576,"This is the maximum size in bytes of a WRITE request
    supported by the NFS gateway. If you change this, make sure you
    also update the nfs mount's wsize(add wsize= # of bytes to the 
    mount directive)."
