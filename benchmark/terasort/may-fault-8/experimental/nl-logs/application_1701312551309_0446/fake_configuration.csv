,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,mapreduce.reduce.shuffle.fetch.retry.timeout-ms,30000,"Timeout value for fetcher to retry to fetch again when some
  non-fatal failure happens because of some events like NM restart."
2,yarn.nodemanager.container-manager.thread-count,20,
3,dfs.datanode.max.nodes.to.report,5,"Number of nodes to include in JSON report. We will return nodes with
    the highest number of votes from peers."
4,dfs.namenode.lease-recheck-interval-ms,2000,"During the release of lease a lock is hold that make any
    operations on the namenode stuck. In order to not block them during
    a too long duration we stop releasing lease after this max lock limit."
5,yarn.nodemanager.localizer.cache.target-size-mb,10240,
6,dfs.webhdfs.netty.high.watermark,65535,High watermark configuration to Netty for Datanode WebHdfs.
7,yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs,20,
8,yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size,10,
9,dfs.client.write.byte-array-manager.count-limit,2048,The maximum number of arrays allowed for each array length.
