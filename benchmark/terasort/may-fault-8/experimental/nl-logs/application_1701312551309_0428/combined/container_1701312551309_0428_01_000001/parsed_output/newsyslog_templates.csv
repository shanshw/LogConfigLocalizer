EventId,EventTemplate,Occurrences
19b75bb3,Created MRAppMaster for application appattempt_<*>_<*>_<*>,1
b6c60981,Updating Configuration,1
0cd5c477,"Executing with tokens: [Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)]",1
70f56aad,resource-types.xml not found,1
860c743d,Unable to find 'resource-types.xml'.,1
0594ecc2,Using mapred newApiCommitter.,1
c0c8618d,OutputCommitter set in config null,1
9c2ab4d0,"No output committer factory defined, defaulting to FileOutputCommitterFactory",1
24f60e3d,File Output Committer Algorithm version is <*>,1
d1f83c9a,"FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false",1
d79644a2,OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter,1
3a2b3aef,Registering class <*> for class <*>,9
fb1f4268,Default file system [hdfs://2f08f873c798:<*>],3
3a03968c,Emitting job history data to the timeline server is not enabled,1
7a3d0110,Loaded properties from hadoop-metrics2.properties,1
becc4e71,Scheduled Metric snapshot period at <*> second(s).,1
fc657c96,MRAppMaster metrics system started,1
080bfa16,Adding job token for job_<*>_<*> to jobTokenSecretManager,1
1351aab1,Not uberizing job_<*>_<*> because: not enabled; too many maps; too much RAM;,1
7ee6a6bc,Input size for job job_<*>_<*> = <*>. Number of splits = <*>,1
691cf50f,Number of reduces for job job_<*>_<*> = <*>,1
c245fdf9,job_<*>_0428Job Transitioned from NEW to INITED,1
8cfccb68,"MRAppMaster launching normal, non-uberized, multi-container job job_<*>_<*>.",1
4800a8aa,"Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: <*>, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.",2
55039769,Listener at <*>,2
70066a26,Starting Socket Reader #<*> for port <*>,2
8c4d0a72,Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server,1
ccc17099,IPC Server Responder: starting,2
73b103d7,IPC Server listener on <*>: starting,2
3592ea3d,Instantiated MRClientService at cf6e5ca2712c<*>,1
bb7ebcdd,Logging initialized @2362ms to org.eclipse.jetty.util.log.Slf4jLog,1
9c1a3d53,"Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret",1
0859dbfb,Http request log for http.requests.mapreduce is not defined,1
a8927e0e,Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter),1
ae2086c0,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context <*>,2
5ba9445a,Registered webapp guice modules,1
8aa20788,Jetty bound to port <*>,1
16a015cc,jetty-<*>.<*>.<*>.v20230217; built: <*>-<*>-17T08:<*>:<*>.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm <*>.<*>.<*>+<*>-post-Ubuntu-1ubuntu120.<*>,1
bacbae49,DefaultSessionIdManager workerName=node<*>,1
9ee7bbd8,"No SessionScavenger set, using defaults",1
11ab4b15,node0 Scavenging every 660000ms,1
00ac854a,Started <*>,3
ca519185,"Started ServerConnector@7b5b5bfe{HTTP/<*>.<*>, (http/<*>.<*>)}{<*>}",1
0923c3bb,Web app mapreduce started at <*>,1
e79de774,JOB_CREATE job_<*>_<*>,1
8b67f3e3,"Service <*> failed in state <*> For input string: ""<*>.<*>"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceInit(RMCommunicator.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.serviceInit(RMContainerRequestor.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceInit(RMContainerAllocator.java:<*>) at org.apache.hadoop.service.AbstractService.init(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.serviceStart(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$<*>.run(MRAppMaster.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:<*>)",3
f88b4e72,Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>,1
c02382a8,Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>,1
4a3798b7,"In stop, writing event <*>",2
10edc0f1,"Event Writer setup for JobId: job_<*>_<*>, File: hdfs://2f08f873c798:<*>/tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>/job_<*>_<*>_<*>.jhist",1
6de59625,Stopped JobHistoryEventHandler. super.stop(),1
81190c6b,Skipping cleaning up the staging dir. assuming AM will be retried.,1
fa5d86c2,Stopping server on <*>,1
da6217eb,Stopping IPC Server listener on <*>,1
8429e6cc,Stopping IPC Server Responder,1
f495a4dd,TaskHeartbeatHandler thread interrupted,1
4594e7ea,TaskAttemptFinishingMonitor thread interrupted,1
e446a849,"Error starting MRAppMasterjava.lang.NumberFormatException: For input string: ""<*>.<*>"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceInit(RMCommunicator.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.serviceInit(RMContainerRequestor.java:<*>) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceInit(RMContainerAllocator.java:<*>) at org.apache.hadoop.service.AbstractService.init(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.serviceStart(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$<*>.run(MRAppMaster.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:<*>)",1
f2dc02db,"Exiting with status <*>: java.lang.NumberFormatException: For input string: ""<*>.<*>""",1
