,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,mapreduce.job.split.metainfo.maxsize,10000000,"The maximum permissible size of the split metainfo file.
  The MapReduce ApplicationMaster won't attempt to read submitted split metainfo
  files bigger than this configured value.
  No limits if set to -1."
2,hadoop.security.kms.client.encrypted.key.cache.size,500,Size of the EncryptedKeyVersion cache Queue for each key
3,ftp.bytes-per-checksum,512,"The number of bytes per checksum.  Must not be larger than
  ftp.stream-buffer-size"
4,yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory,10,
5,dfs.http.client.retry.max.attempts,10,"Specify the max number of retry attempts for WebHDFS client,
    if the difference between retried attempts and failovered attempts is
    larger than the max number of retry attempts, there will be no more
    retries."
6,yarn.nodemanager.delete.debug-delay-sec,0,
7,yarn.nm.liveness-monitor.expiry-interval-ms,600000,
8,yarn.timeline-service.client.retry-interval-ms,1000,
9,mapreduce.map.cpu.vcores,1,"The number of virtual cores to request from the scheduler for
  each map task."
