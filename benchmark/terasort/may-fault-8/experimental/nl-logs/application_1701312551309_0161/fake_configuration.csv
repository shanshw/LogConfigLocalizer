,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.nodemanager.container.stderr.tail.bytes,4096,
2,fs.s3a.connection.timeout,200000,Socket connection timeout in milliseconds.
3,yarn.dispatcher.cpu-monitor.samples-per-min,60,
4,fs.s3a.executor.capacity,16,"The maximum number of submitted tasks which is a single
    operation (e.g. rename(), delete()) may submit simultaneously for
    execution -excluding the IO-heavy block uploads, whose capacity
    is set in ""fs.s3a.fast.upload.active.blocks""

    All tasks are submitted to the shared thread pool whose size is
    set in ""fs.s3a.threads.max""; the value of capacity should be less than that
    of the thread pool itself, as the goal is to stop a single operation
    from overloading that thread pool."
5,dfs.namenode.decommission.max.concurrent.tracked.nodes,100,"The maximum number of decommission-in-progress or
    entering-maintenance datanodes nodes that will be tracked at one time by
    the namenode. Tracking these datanode consumes additional NN memory
    proportional to the number of blocks on the datnode. Having a conservative
    limit reduces the potential impact of decommissioning or maintenance of
    a large number of nodes at once.
      
    A value of 0 means no limit will be enforced."
6,yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms,10,
7,mapreduce.job.reducer.preempt.delay.sec,0,"The threshold (in seconds) after which an unsatisfied
      mapper request triggers reducer preemption when there is no anticipated
      headroom. If set to 0 or a negative value, the reducer is preempted as
      soon as lack of headroom is detected. Default is 0."
8,mapreduce.client.submit.file.replication,10,"The replication level for submitted job files.  This
  should be around the square root of the number of nodes."
9,ipc.[port_number].weighted-cost.handler,1,"The weight multiplier to apply to the time spent in the
    HANDLER phase which do not involve holding a lock.
    See org.apache.hadoop.ipc.ProcessingDetails.Timing for more details on
    this phase. This property applies to WeightedTimeCostProvider."
