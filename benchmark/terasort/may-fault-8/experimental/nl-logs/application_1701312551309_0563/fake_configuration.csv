,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.client.read.striped.threadpool.size,18,"The maximum number of threads used for parallel reading
    in striped layout."
2,yarn.nodemanager.container-log-monitor.total-size-limit-bytes,10000000000,
3,mapreduce.job.end-notification.retry.attempts,0,"The number of times the submitter of the job wants to retry job
    end notification if it fails. This is capped by
    mapreduce.job.end-notification.max.attempts"
4,dfs.edit.log.transfer.timeout,30000,"Socket timeout for edit log transfer in milliseconds. This timeout
    should be configured such that normal edit log transfer for journal
    node syncing can complete successfully."
5,dfs.datanode.data.transfer.bandwidthPerSec,0,"Specifies the maximum amount of bandwidth that the data transfering can utilize for transfering block when
      BlockConstructionStage is
      PIPELINE_SETUP_CREATE and clientName is empty.
      When the bandwidth value is zero, there is no limit."
6,file.bytes-per-checksum,512,"The number of bytes per checksum.  Must not be larger than
  file.stream-buffer-size"
7,ftp.replication,3,Replication factor
8,dfs.namenode.full.block.report.lease.length.ms,300000,"The number of milliseconds that the NameNode will wait before invalidating
    a full block report lease.  This prevents a crashed DataNode from
    permanently using up a full block report lease."
9,dfs.namenode.num.extra.edits.retained,1000000,"The number of extra transactions which should be retained
  beyond what is minimally necessary for a NN restart.
  It does not translate directly to file's age, or the number of files kept,
  but to the number of transactions (here ""edits"" means transactions).
  One edit file may contain several transactions (edits).
  During checkpoint, NameNode will identify the total number of edits to retain as extra by
  checking the latest checkpoint transaction value, subtracted by the value of this property.
  Then, it scans edits files to identify the older ones that don't include the computed range of
  retained transactions that are to be kept around, and purges them subsequently.
  The retainment can be useful for audit purposes or for an HA setup where a remote Standby Node may have
  been offline for some time and need to have a longer backlog of retained
  edits in order to start again.
  Typically each edit is on the order of a few hundred bytes, so the default
  of 1 million edits should be on the order of hundreds of MBs or low GBs.

  NOTE: Fewer extra edits may be retained than value specified for this setting
  if doing so would mean that more segments would be retained than the number
  configured by dfs.namenode.max.extra.edits.segments.retained."
