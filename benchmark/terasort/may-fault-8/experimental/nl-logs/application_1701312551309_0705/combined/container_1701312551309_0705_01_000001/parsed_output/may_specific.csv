0,1
01d5535c,"Job init failedjava.lang.NumberFormatException: For input string: ""<*>.<*>"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:<*>) at java.base/java.io.DataInputStream.readFully(DataInputStream.java:<*>) at java.base/java.io.DataInputStream.readFully(DataInputStream.java:<*>) at org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(SplitMetaInfoReader.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.createSplits(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory.access$<*>(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$<*>.run(MRAppMaster.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:<*>)"
9c9cab88,Instantiated MRClientService at ed761ad59d44<*>
f773b569,Logging initialized @2162ms to org.eclipse.jetty.util.log.Slf4jLog
64af699d,jetty-<*>.<*>.<*>.v20230217; built: <*>-<*>-17T08:<*>:<*>.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm <*><*>-post-Ubuntu-0ubuntu120.<*>
0fcdc0c2,node0 Scavenging every 600000ms
3e0cf2e1,"Started ServerConnector@fa5f81c{HTTP/<*>.<*>, (http/<*>.<*>)}{<*>}"
7bebd640,job_<*>_0705Job Transitioned from <*> to <*>
288b932d,Processing the event EventType: JOB_ABORT
4a3798b7,"In stop, writing event <*>"
60fff1df,Copying hdfs://2f08f873c798:<*>/tmp/hadoop-yarn/staging/root/.staging/job_<*>_<*>/job_<*>_<*>_<*>.jhist to hdfs://2f08f873c798:<*>/tmp/hadoop-yarn/staging/history/done_intermediate/root/job_<*>_<*>-<*>-root-TeraSort-<*>-<*>-<*>-FAILED-default-<*>.jhist_tmp
77fee706,"Service <*> failed in state STOPPEDjava.lang.NumberFormatException: For input string: ""<*>.<*>"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:<*>) at java.base/java.io.DataInputStream.read(DataInputStream.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.moveToDoneNow(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>)"
025d92d3,"When stopping the service JobHistoryEventHandlerjava.lang.NumberFormatException: For input string: ""<*>.<*>"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:<*>) at java.base/java.io.DataInputStream.read(DataInputStream.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.moveToDoneNow(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>)"
7a8a697d,"Setting job diagnostics to Job init failed : java.lang.NumberFormatException: For input string: ""<*>.<*>"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:<*>) at java.base/java.io.DataInputStream.readFully(DataInputStream.java:<*>) at java.base/java.io.DataInputStream.readFully(DataInputStream.java:<*>) at org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(SplitMetaInfoReader.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.createSplits(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory.access$<*>(StateMachineFactory.java:<*>) at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$<*>.run(MRAppMaster.java:<*>) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:<*>) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:<*>)"
03ca4927,History url is null
8cc364e1,"Graceful stop failed. Exiting..java.lang.NumberFormatException: For input string: ""<*>.<*>"" at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at java.base/java.lang.Integer.parseInt(Integer.java:<*>) at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:<*>) at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:<*>) at java.base/java.io.DataInputStream.read(DataInputStream.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.moveToDoneNow(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:<*>) at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:<*>) at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:<*>) at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:<*>) at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:<*>) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$<*>.run(MRAppMaster.java:<*>)"
f2dc02db,"Exiting with status <*>: java.lang.NumberFormatException: For input string: ""<*>.<*>"""
