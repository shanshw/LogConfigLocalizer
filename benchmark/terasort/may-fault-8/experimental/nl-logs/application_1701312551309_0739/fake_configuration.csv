,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.block.scanner.volume.bytes.per.second,1048576,"If this is configured less than or equal to zero, the DataNode's block scanner will be disabled.  If this
        is positive, this is the number of bytes per second that the DataNode's
        block scanner will try to scan from each volume."
2,fs.s3a.fast.upload.active.blocks,4,"Maximum Number of blocks a single output stream can have
    active (uploading, or queued to the central FileSystem
    instance's pool of queued operations.

    This stops a single stream overloading the shared thread pool."
3,dfs.ha.tail-edits.namenode-retries,3,Number of retries to use when contacting the namenode when tailing the log.
4,yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts,3,"The number of client retries on socket timeouts to the AM - before
    reconnecting to the RM to fetch Application Status.
    In other words, it is the ipc.client.connect.max.retries.on.timeouts to be used during
    reconnecting to the RM and fetching Application Status."
5,dfs.namenode.retrycache.expirytime.millis,600000,The time for which retry cache entries are retained.
6,dfs.datanode.slow.io.warning.threshold.ms,300,"The threshold in milliseconds at which we will log a slow
    io warning in a datanode. By default, this parameter is set to 300
    milliseconds."
7,mapreduce.reduce.shuffle.fetch.retry.interval-ms,1000,"Time of interval that fetcher retry to fetch again when some
  non-fatal failure happens because of some events like NM restart."
8,dfs.client.read.shortcircuit.streams.cache.expiry.ms,300000,"This controls the minimum amount of time
    file descriptors need to sit in the client cache context
    before they can be closed for being inactive for too long."
9,dfs.namenode.checkpoint.check.period,60,"The SecondaryNameNode and CheckpointNode will poll the NameNode
  every 'dfs.namenode.checkpoint.check.period' seconds to query the number
  of uncheckpointed transactions. Support multiple time unit suffix(case insensitive),
  as described in dfs.heartbeat.interval.If no time unit is specified then
  seconds is assumed."
