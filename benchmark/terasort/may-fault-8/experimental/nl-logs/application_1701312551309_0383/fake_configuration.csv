,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.namenode.edit.log.autoroll.check.interval.ms,300000,"How often an active namenode will check if it needs to roll its edit log,
    in milliseconds."
2,dfs.client.deadnode.detection.probe.suspectnode.interval.ms,300,Interval time in milliseconds for probing suspect node behavior.
3,dfs.datanode.lock-reporting-threshold-ms,300,"When thread waits to obtain a lock, or a thread holds a lock for
    more than the threshold, a log message will be written. Note that
    dfs.lock.suppress.warning.interval ensures a single log message is
    emitted per interval for waiting threads and a single message for holding
    threads to avoid excessive logging."
4,dfs.ha.log-roll.period,120,"How often, in seconds, the StandbyNode should ask the active to
    roll edit logs. Since the StandbyNode only reads from finalized
    log segments, the StandbyNode will only be as up-to-date as how
    often the logs are rolled. Note that failover triggers a log roll
    so the StandbyNode will be up to date before it becomes active.
    Support multiple time unit suffix(case insensitive), as described
    in dfs.heartbeat.interval.If no time unit is specified then seconds
    is assumed."
5,dfs.client.write.max-packets-in-flight,80,The maximum number of DFSPackets allowed in flight.
6,dfs.storage.policy.satisfier.datanode.cache.refresh.interval.ms,300000,"How often to refresh the datanode storages cache in milliseconds. This cache
    keeps live datanode storage reports fetched from namenode. After elapsed time,
    it will again fetch latest datanodes from namenode.
    By default, this parameter is set to 5 minutes."
7,dfs.client.datanode-restart.timeout,30,"Expert only. The time to wait, in seconds, from reception of an
    datanode shutdown notification for quick restart, until declaring
    the datanode dead and invoking the normal recovery mechanisms.
    The notification is sent by a datanode when it is being shutdown
    using the shutdownDatanode admin command with the upgrade option.
    Support multiple time unit suffix(case insensitive), as described
    in dfs.heartbeat.interval.If no time unit is specified then seconds
    is assumed."
8,dfs.http.client.retry.max.attempts,10,"Specify the max number of retry attempts for WebHDFS client,
    if the difference between retried attempts and failovered attempts is
    larger than the max number of retry attempts, there will be no more
    retries."
9,dfs.balancer.movedWinWidth,5400000,"Window of time in ms for the HDFS balancer tracking blocks and its
    locations."
