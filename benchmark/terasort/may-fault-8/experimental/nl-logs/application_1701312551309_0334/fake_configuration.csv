,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.app.mapreduce.shuffle.log.backups,0,"If yarn.app.mapreduce.shuffle.log.limit.kb and
    yarn.app.mapreduce.shuffle.log.backups are greater than zero
    then a ContainerRollngLogAppender is used instead of ContainerLogAppender
    for syslog.shuffle. See
    org.apache.log4j.RollingFileAppender.maxBackupIndex"
2,yarn.timeline-service.ttl-ms,604800000,
3,hadoop.shell.safely.delete.limit.num.files,100,"Used by -safely option of hadoop fs shell -rm command to avoid
      accidental deletion of large directories. When enabled, the -rm command
      requires confirmation if the number of files to be deleted is greater than
      this limit.  The default limit is 100 files. The warning is disabled if
      the limit is 0 or the -safely is not specified in -rm command."
4,dfs.webhdfs.netty.low.watermark,32768,Low watermark configuration to Netty for Datanode WebHdfs.
5,mapreduce.reduce.shuffle.retry-delay.max.ms,60000,"The maximum number of ms the reducer will delay before retrying
  to download map data."
6,ha.failover-controller.graceful-fence.rpc-timeout.ms,5000,Timeout that the FC waits for the old active to go to standby
7,yarn.resourcemanager.fs.state-store.retry-interval-ms,1000,
8,yarn.nodemanager.delete.thread-count,4,
9,dfs.content-summary.sleep-microsec,500,"The length of time in microseconds to put the thread to sleep, between reaquiring the locks
    in content summary computation."
