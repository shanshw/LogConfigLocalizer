,name,value,description
0,io.bytes.per.checksum,0,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,hadoop.hdfs.configuration.version,1,version of this configuration file
2,yarn.timeline-service.writer.flush-interval-seconds,60,
3,yarn.resourcemanager.delegation-token-renewer.thread-count,50,
4,fs.trash.checkpoint.interval,0,"Number of minutes between trash checkpoints.
  Should be smaller or equal to fs.trash.interval. If zero,
  the value is set to the value of fs.trash.interval.
  Every time the checkpointer runs it creates a new checkpoint
  out of current and removes checkpoints created more than
  fs.trash.interval minutes ago."
5,hadoop.fuse.timer.period,5,"The number of seconds between cache expiry checks in fuse_dfs. Lower values
    will result in fuse_dfs noticing changes to Kerberos ticket caches more
    quickly."
6,dfs.image.transfer-bootstrap-standby.bandwidthPerSec,0,"Maximum bandwidth used for transferring image to bootstrap standby
      namenode, in bytes per second.
      A default value of 0 indicates that throttling is disabled. This default
      value should be used in most cases, to ensure timely HA operations.
      The maximum bandwidth used for regular image transfers is configured
      with dfs.image.transfer.bandwidthPerSec.
      Support multiple size unit suffix(case insensitive), as described in
      dfs.blocksize."
7,dfs.namenode.write-lock-reporting-threshold-ms,5000,"When a write lock is held on the namenode for a long time,
    this will be logged as the lock is released. This sets how long the
    lock must be held for logging to occur."
8,ftp.replication,3,Replication factor
9,dfs.datanode.cache.revocation.polling.ms,500,"How often the DataNode should poll to see if the clients have
    stopped using a replica that the DataNode wants to uncache."
