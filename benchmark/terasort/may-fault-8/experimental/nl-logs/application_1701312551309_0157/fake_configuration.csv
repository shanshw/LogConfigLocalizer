,name,value,description
0,io.bytes.per.checksum,1706081678,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.namenode.list.encryption.zones.num.responses,100,"When listing encryption zones, the maximum number of zones
    that will be returned in a batch. Fetching the list incrementally in
    batches improves namenode performance."
2,io.mapfile.bloom.size,1048576,"The size of BloomFilter-s used in BloomMapFile. Each time this many
  keys is appended the next BloomFilter will be created (inside a DynamicBloomFilter).
  Larger values minimize the number of filters, which slightly increases the performance,
  but may waste too much space if the total number of keys is usually much smaller
  than this number."
3,dfs.namenode.block.deletion.increment,1000,"The number of block deletion increment.
      This setting will control the block increment deletion rate to
      ensure that other waiters on the lock can get in."
4,yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms,100,
5,hadoop.registry.zk.retry.ceiling.ms,60000,"Zookeeper retry limit in milliseconds, during
      exponential backoff.

      This places a limit even
      if the retry times and interval limit, combined
      with the backoff policy, result in a long retry
      period"
6,dfs.client.hedged.read.threshold.millis,500,"Configure 'hedged' reads in DFSClient. This is the number of milliseconds
    to wait before starting up a 'hedged' read."
7,nfs.rtmax,1048576,"This is the maximum size in bytes of a READ request
    supported by the NFS gateway. If you change this, make sure you
    also update the nfs mount's rsize(add rsize= # of bytes to the 
    mount directive)."
8,yarn.resourcemanager.am.max-attempts,2,
9,ipc.[port_number].scheduler.priority.levels,4,"How many priority levels to use within the scheduler and call
    queue. This property applies to RpcScheduler and CallQueue."
