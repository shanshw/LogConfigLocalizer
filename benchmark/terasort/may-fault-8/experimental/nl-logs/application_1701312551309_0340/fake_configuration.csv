,name,value,description
0,io.bytes.per.checksum,-62709662,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.qjournal.write-txns.timeout.ms,20000,"Write timeout in milliseconds when writing to a quorum of remote
    journals."
2,yarn.nodemanager.container-retry-minimum-interval-ms,1000,
3,mapreduce.am.max-attempts,2,"The maximum number of application attempts. It is a
  application-specific setting. It should not be larger than the global number
  set by resourcemanager. Otherwise, it will be override. The default number is
  set to 2, to allow at least one retry for AM."
4,dfs.datanode.cache.revocation.timeout.ms,900000,"When the DFSClient reads from a block file which the DataNode is
    caching, the DFSClient can skip verifying checksums.  The DataNode will
    keep the block file in cache until the client is done.  If the client takes
    an unusually long time, though, the DataNode may need to evict the block
    file from the cache anyway.  This value controls how long the DataNode will
    wait for the client to release a replica that it is reading without
    checksums."
5,yarn.resourcemanager.epoch.range,0,
6,dfs.storage.policy.satisfier.recheck.timeout.millis,60000,"Blocks storage movements monitor re-check interval in milliseconds.
    This check will verify whether any blocks storage movement results arrived from DN
    and also verify if any of file blocks movements not at all reported to DN
    since dfs.storage.policy.satisfier.self.retry.timeout.
    The default value is 1 * 60 * 1000 (1 mins)"
7,hadoop.registry.zk.retry.times,5,Zookeeper connection retry count before failing
8,dfs.datanode.ec.reconstruction.stripedread.timeout.millis,5000,Datanode striped read timeout in milliseconds.
9,yarn.nodemanager.resource.percentage-physical-cpu-limit,100,
