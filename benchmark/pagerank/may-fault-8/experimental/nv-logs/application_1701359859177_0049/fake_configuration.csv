,name,value,description
0,io.bytes.per.checksum,333110087,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.datanode.ec.reconstruct.read.bandwidthPerSec,0,"Specifies the maximum amount of bandwidth that the EC reconstruction can utilize for reading.
      When the bandwidth value is zero, there is no limit."
2,dfs.client.test.drop.namenode.response.number,0,"The number of Namenode responses dropped by DFSClient for each RPC call.  Used
    for testing the NN retry cache."
3,mapreduce.client.submit.file.replication,10,"The replication level for submitted job files.  This
  should be around the square root of the number of nodes."
4,mapreduce.task.exit.timeout,60000,"The number of milliseconds before a task will be
  terminated if it stays in finishing state for too long.
  After a task attempt completes from TaskUmbilicalProtocol's point of view,
  it will be transitioned to finishing state. That will give a chance for the
  task to exit by itself."
5,yarn.scheduler.minimum-allocation-vcores,1,
6,dfs.http.client.retry.max.attempts,10,"Specify the max number of retry attempts for WebHDFS client,
    if the difference between retried attempts and failovered attempts is
    larger than the max number of retry attempts, there will be no more
    retries."
7,yarn.nodemanager.container-executor.exit-code-file.timeout-ms,2000,
8,mapreduce.job.cache.limit.max-resources-mb,0,"The maximum size (in MB) a map reduce job is allowed to submit
    for localization via files, libjars, archives, and jobjar command line
    arguments and through the distributed cache. If set to 0 the limit is
    ignored."
9,yarn.nodemanager.local-cache.max-files-per-directory,8192,
