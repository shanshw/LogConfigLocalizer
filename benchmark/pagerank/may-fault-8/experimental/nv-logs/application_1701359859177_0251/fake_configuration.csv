,name,value,description
0,io.bytes.per.checksum,-277791361,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.namenode.name.cache.threshold,10,"Frequently accessed files that are accessed more times than this
    threshold are cached in the FSDirectory nameCache."
2,dfs.namenode.snapshot.skiplist.interval,10,"The interval after which the skip levels will be formed in the skip list
    for storing directory snapshot diffs. By default, value is set to 10."
3,dfs.namenode.fs-limits.max-blocks-per-file,10000,"Maximum number of blocks per file, enforced by the Namenode on
        write. This prevents the creation of extremely large files which can
        degrade performance."
4,dfs.namenode.stale.datanode.minimum.interval,3,"Minimum number of missed heartbeats intervals for a datanode to
    be marked stale by the Namenode.  The actual interval is calculated as
    (dfs.namenode.stale.datanode.minimum.interval * dfs.heartbeat.interval)
    in seconds.  If this value is greater than the property
    dfs.namenode.stale.datanode.interval, then the calculated value above
    is used."
5,dfs.namenode.redundancy.queue.restart.iterations,2400,"When picking blocks from the low redundancy queues, reset the
    bookmarked iterator after the set number of iterations to ensure any blocks
    which were not processed on the first pass are retried before the iterators
    would naturally reach their end point. This ensures blocks are retried
    more frequently when there are many pending blocks or blocks are
    continuously added to the queues preventing the iterator reaching its
    natural endpoint.
    The default setting of 2400 combined with the default of
    dfs.namenode.redundancy.interval.seconds means the iterators will be reset
    approximately every 2 hours.
    Setting this parameter to zero disables the feature and the iterators will
    be reset only when the end of all queues has been reached."
6,mapreduce.reduce.cpu.vcores,1,"The number of virtual cores to request from the scheduler for
  each reduce task."
7,dfs.client.failover.sleep.base.millis,500,"Expert only. The time to wait, in milliseconds, between failover
    attempts increases exponentially as a function of the number of
    attempts made so far, with a random factor of +/- 50%. This option
    specifies the base value used in the failover calculation. The
    first failover will retry immediately. The 2nd failover attempt
    will delay at least dfs.client.failover.sleep.base.millis
    milliseconds. And so on."
8,yarn.nodemanager.container-manager.thread-count,20,
9,dfs.namenode.top.num.users,10,Number of top users returned by the top tool
